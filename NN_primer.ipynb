{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unrolling neural network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch, numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "SEED = 4200\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy case models and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)  # Reshape y_train to match model output shape\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)  # Reshape y_test to match model output shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(13, 30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30, 1)\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-1, weight_decay = 5e-4)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple training loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 108.9392\n",
      "Epoch [20/100], Loss: 43.4876\n",
      "Epoch [30/100], Loss: 24.4725\n",
      "Epoch [40/100], Loss: 18.0850\n",
      "Epoch [50/100], Loss: 14.4142\n",
      "Epoch [60/100], Loss: 12.0501\n",
      "Epoch [70/100], Loss: 10.4739\n",
      "Epoch [80/100], Loss: 9.5392\n",
      "Epoch [90/100], Loss: 8.7902\n",
      "Epoch [100/100], Loss: 8.1955\n",
      "Test Loss: 12.1529\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    # Forward pass\n",
    "    \n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Store loss value\n",
    "    train_losses.append(loss.item())\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{100}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    test_loss = criterion(test_outputs, y_test_tensor)\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25031d19ed0>]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAAGhCAYAAABVk3+7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA5FklEQVR4nO3deXhU5cH+8fvMTPZlSAgEshEgYQkIYQmIgixGEXfEpdoKoqJVWm3ppm+rvu1rq60/LVXjXhRcUau4oBah7IshQRAFDGENWxayJ2Sbmd8fgVgEJIFJzizfz3XlD2bOnHOT6zrMzXOe8xzD5XK5BAAA4AEsZgcAAAA4hmICAAA8BsUEAAB4DIoJAADwGBQTAADgMSgmAADAY1BMAACAx7CZHaCtnE6nDhw4oIiICBmGYXYcAADQCi6XS1VVVYqLi5PFcupxEa8rJgcOHFBiYqLZMQAAwBkoKChQQkLCKd/3umISEREhqfkvFhkZaXIaAADQGpWVlUpMTGz5Hj8Vrysmxy7fREZGUkwAAPAyp5uGweRXAADgMSgmAADAY1BMAACAx/CaYpKVlaW0tDRlZGSYHQUAALQTw+VyucwO0RaVlZWy2+2qqKhg8isAAF6itd/fXjNiAgAAfB/FBAAAeAyKCQAA8BgUEwAA4DEoJgAAwGNQTAAAgMegmAAAAI9BMQEAAB6DYgIAADwGxQQAAHgMrykmPCsHAADfx7NyAABAu+NZOQAAwOtQTAAAgMegmAAAAI9BMQEAAB6DYgIAADyGzewAZ+qiJ5bLFhzm1n2GBFqVnthJGclRykiOVs+YMBmG4dZjAACAU/PaYnKwok6WOvcP+OQXVevd3H2SpJjwQA3vEa2MntHKSI5SWvdI2awMMgEA0F68dh2TVd/sUXiEe9cxKa1pUM6eUq3fVaaN+8rV0OQ87v3QQKuGJjWPpmQkR2lIUpRCAq1uzQAAgC9q7TomXltM2nuBtfomhzbvq1D27lLl7C5Tzu5SVdY1HbeNzWJoYLy95dLP8ORoRYcFtlsmAAC8FcXEzZxOl/KKqrR+V6nW7y7T+t2lOlhRd8J2KV3DW4pKRnK0EqJCmKcCAPB7FJN25nK5tL/8iNbvLlX2ruYRle1F1Sds1y0yuGWOSkZytPrGRshioagAAPwLxcQEpTUNyt3TPJqyfnepNu+rUJPz+F9vRLBNw3tEaXhytEb0jNagBLuCbMxTAQD4Np8rJllZWcrKypLD4VBeXp5HFpPvO9Lg0JcFZco5eulnw54y1TQ4jtsm0GbR4AR7y6WfoT2iZA8JMCkxAADtw+eKyTGePGJyOk0Op7YerGoZUVm/u1Ql1Q3HbWMYUt/YCI3oGd1SVrrZg01KDACAe1BMvIDL5dLuw7VHJ9Q2/+w+XHvCdonRIcr4r/VUencJZ0ItAMCrUEy8VFFVnXJ2lyl7V6ly9pRqy4FKfW+aiqLDAjW8x9E7f3pGa0BcpAJY+A0A4MEoJj6iqq5RX+4tbxlR+XJvueq/t/BbSIBVQ5I6tVz6GZLUSWFBXruoLwDAB1FMfFRDk1Ob91cop2WeSpkqjjQet43VYmhAXGRLURmeHKWY8CCTEgMAQDHxG06nS/nF1c0l5ejib/vLj5ywXa8uYcfNU0mKDmWeCgCgw1BM/Nj+8iPfjajsKtO3hVUnbNM1Iqi5pPSIUkbPaPXrFikrC78BANoJxQQtymubF3479tyfr/aVq9HxvYXfgmwa2iOqZYXawYmdFBzAwm8AAPegmOCU6hod2lRQ3jJHJXdPmarrj39AYaDVoiFJnfSbiX01PDnapKQAAF9BMUGrOZwubT1YefTyT/PISnFVvaTmBd+mjUrWbyb25U4fAMAZo5jgjLlcLu05XKtnluXr7Zx9kqT4TiH6yzXnaGyfLianAwB4o9Z+f7MqF05gGIaSY8L0t2sH67XbRiohKkT7y49o2pxszXp7o8pqGk6/EwAAzgDFBD9odGqMFv3yAt16fk8ZhvTehv266O/LtfCrg/KywTYAgBegmOC0QgNtevCKNP3rrvOU2jVcJdUNmvnGBt35aq4KK+vMjgcA8CEUE7Ta0KQofXzPaN1zYapsFkOLthQq84nlmr9+L6MnAAC3oJigTYJsVs26qI8+vme0BifYVVXXpN/9a7N+/NIX2nuSJyMDANAWFBOckX7dIvXe3efr95f2V3CARWt2HNbFs5frpZU75fj+45ABAGglrykmWVlZSktLU0ZGhtlRcJTVYmjGBb302b0X6Nxe0aprdOrhhVt1zbNr9O2hE5fBBwDgdFjHBG7hcrn01voC/WXhVlXVNynAaujucSmaOT5FgTav6b8AgHbCOiboUIZh6MYRSfp81lhl9o9Vo8OlfyzZrsufWqmNBeVmxwMAeAmKCdyqmz1YL04dpqdvGqLOYYHKK6zWNc+s1sMfb1FtQ9PpdwAA8GsUE7idYRi6fFCcFs8aq2uGxMvpkl5atUuXzF6pNfklZscDAHgwignaTVRYoJ64IV0vT89QnD1Ye0trddNLX+i+f32liiONZscDAHggigna3fi+XbVo1lhNHdVDkvTW+gJd9MRy/fubQyYnAwB4GooJOkR4kE1/umqg3r5zlHrFhKmoql53vpqrma9vUHFVvdnxAAAegmKCDjWiZ7Q+uXeM7h7XW1aLoYWbDyrzieX6V+4+lrUHAFBM0PGCA6z67SX99MHM8zUgLlIVRxr1q3c2adrL67WvjGXtAcCfUUxgmoHxdi2Yeb5+d0k/BdosWpFXrIv/vkJz1+yWk2XtAcAvUUxgqgCrRXeN661P7x2jEcnRqm1w6KEPv9H1z69VflG12fEAAB2MYgKP0LtLuN6641z939UDFRZoVc6eMl36j5XKWpqvRofT7HgAgA5CMYHHsFgM3XxuDy2aNVbj+nZRg8Opx/79ra58erU276swOx4AoANQTOBx4juF6OVbMvT3GwYrKjRAWw9W6upnVuuRT7eqrtFhdjwAQDuimMAjGYahyUMS9PmssbpicJwcTpeeX75Tk/6xUut2HjY7HgCgnVBM4NFiwoP01I1D9OLU4YqNDNKukhr96IV1+v37m1VVx7L2AOBrKCbwChelxerzWWN144gkSdLrX+zVJbNXqqCUdU8AwJdQTOA1IoMD9Mg15+iNGSOVGB2i/eVHNO3lbJXVNJgdDQDgJhQTeJ3zesfo7TtHqbs9WDuLa3T7vBwmxQKAj6CYwCt1t4do7q0jFBlsU+6eMv38zS/lYLVYAPB6FBN4rT6xEXppWoYCbRZ9vqVQD37wNQ8CBAAv5zXFJCsrS2lpacrIyDA7CjzIiJ7RevJH6TKM5gmxWUvzzY4EADgLhsvL/otZWVkpu92uiooKRUZGmh0HHmLumt166MNvJEl/u3aQrh+eaHIiAMB/a+33t9eMmAA/ZNp5ybprXG9J0v3vbdbSb4tMTgQAOBMUE/iM307sq2uGxsvhdOnu1zZoU0G52ZEAAG1EMYHPMAxDf50ySGNSY3Sk0aFbX1mv3SU1ZscCALQBxQQ+JcBq0bM/GaaB8ZE6XNOgaS9nq6S63uxYAIBWopjA54QH2TTnlgwlRodoz+Fa3frKetXUN5kdCwDQChQT+KSuEcGad+tIRYcF6qt9Fbr79Q1qdDjNjgUAOA2KCXxWz5gw/XPacIUEWLU8r1j3v7eZBdgAwMNRTODThiRFKevHQ2S1GHo3d58eX5RndiQAwA+gmMDnTegXqz9fPVCS9PTSfL26bo/JiQAAp0IxgV/40Ygk/TKzjyTpoQ++1r+/OWRyIgDAyVBM4DfuuTBFN45IlNMl3fPml8rZXWp2JADA91BM4DcMw9D/XTVQmf27qr7Jqdvm5ii/qMrsWACA/0IxgV+xWS166sahGpLUSRVHGjVtznoVVtaZHQsAcBTFBH4nJNCqf07LUK+YMO0vP6Jpc7JVWddodiwAgCgm8FPRYYGae+sIdYkI0rZDVbpzXq7qmxxmxwIAv0cxgd9KjA7Vy7dkKCzQqrU7D+vX73wlp5MF2ADATBQT+LWB8XY9d/Mw2SyGPtp0QI98utXsSADg1ygm8HtjUrvosesGSZJeXLlLL63caXIiAPBfFBNA0uQhCbpvUj9J0sMLt+rDTQdMTgQA/oliAhx15wW9dMt5yZKkX7+9SWt2lJgbCAD8EMUEOMowDD1weZouPaebGhxO3TkvV1sPVpodCwD8CsUE+C9Wi6Enrk/XyJ7Rqqpv0i0vZ2t/+RGzYwGA36CYAN8THGDVC1OHq09suAor6zVtTrbKaxvMjgUAfoFiApyEPSRAc28doe72YOUXVev2uTmqa2QBNgBobxQT4BS620M099YRigy2KWdPme5960s5WIANANoVxQT4AX1iI/Ti1OEKtFn0728K9cePvpHLRTkBgPZCMQFOY2Svzpp9Q7oMQ5q3do9eWMECbADQXigmQCtcek53/eGyNEnSI59uYwE2AGgnFBOglW4b3VO3nt9TUvMCbGt3HDY5EQD4HooJ0AZ/uKx/ywJsd7yao7zCKrMjAYBP8ZpikpWVpbS0NGVkZJgdBX7McnQBtozkKFXVNemWOdkqrKwzOxYA+AzD5WW3GFRWVsput6uiokKRkZFmx4GfKq9t0DXPrtHO4hr17x6pt+88VxHBAWbHAgCP1drvb68ZMQE8SafQQM2dPkIx4UHaerBSd7++QY0Op9mxAMDrUUyAM5QYHaqXb8lQaKBVK7eX6L5/bWaNEwA4SxQT4Cyck2BX1k1DZbUY+teGffr753lmRwIAr0YxAc7S+H5d9eerB0qSnvxPvt7M3mtyIgDwXhQTwA1+NCJJ90xIkST9YcHXWrqtyOREAOCdKCaAm/zyoj6aMjRBDqdLd7++QV/tKzc7EgB4HYoJ4CaGYejRKedoTGqMjjQ6dOsr61VQWmt2LADwKhQTwI0CrBY98+Oh6t89UiXVDZr2crbKahrMjgUAXoNiArhZRHCAXpmeoTh7sHYW1+j2eTmqa3SYHQsAvALFBGgHsZHBeuXWEYoItil3T5l+OX+jHE7WOAGA06GYAO2kT2yEXrh5uAKtFn369SH9eeFWsyMBgMejmADtaFTvznrsukGSpDmrd+mllTtNTgQAno1iArSzq9Ljdf+kfpKkhxdu1cKvDpqcCAA8F8UE6AB3XNBLU0f1kCT98u2Nyt5VanIiAPBMFBOgAxiGoYeuGKCL0mLV0OTUjHk5yi+qMjuWJMnpdKmhiScjA/AMFBOgg1gthp780RANSeqkiiONmjZnvYqq6kzL09Dk1FvZezX2/y1Vvwc+1c/e2KCtBytNywMAkmS4vOw57ZWVlbLb7aqoqFBkZKTZcYA2O1xdrynPrtHuw7UaGB+pt+4YpfAgW4cdv6HJqXdyC/TM0h3aX37khPcz+3fVzPEpGpIU1WGZAPi+1n5/U0wAE+wuqdE1z65RaU2DRqfE6FcX99GghE6yWox2O2Z9k0Nvry/Qs8t26EBF80hNl4gg3XlBLw3rEaWXVu3SJ5sP6ti/COendNbM8Ska1auzDKP9cgHwDxQTwMN9ubdMN764TnWNzfM7IoNtOj8lRqNTY3RBahclRoe65Th1jQ7NP1pIDlU2F5KuEUG6a1xv3TgiScEB1pZtdxRX69llO7Tgy/1qOrog3NCkTvrZhBSN79uVggLgjFFMAC+Qu6dUL63cpdX5JaqsazruvR6dQzUmNUajU7poVO/OsocEtGnfdY0OvfHFXj23fIeKquolSd0ig3X3+N66fnjicYXk+/aV1er55Ts1P6egZWJsWvdIzRyfoksGdmvXkR0AvoliAniRJodTm/dXaOX2Eq3aXqINe8taRiyk5omzgxPsGpPaRWNSYzQ4sZMCrCefu17b0HS0kOxUSXVzIYmzB+uu8Sm6fniCgmynLiTfV1RZp5dW7dJr6/aotqH5eT+9u4TprnEpuio97pQZAOD7KCaAF6uub9K6HYe1cnuxVuaXaGdxzXHvRwTZdG7vzrogNUajU7souXOoahscem3dHr2wYqcOH32icXynEM0cn6JrhyUo0HbmJaKspkEvr9mtV1bvahnZSYoO1bxbRyg5JuzM/6IA/AbFBPAh+8uPaNX2Yq3YXqLV+SUqr2087v2EqBDVNjhUerSQJEaH6GfjU3TN0AS3jmpU1TXqtXV79c9VO1VS3aCJA2L1/M3D3bZ/AL6LYgL4KIfTpW8ONF/2Wbm9WLl7ytToaD6NkzuHaub4FF09JL5dL7NsL6zSxbNXyOWSFt4zWgPi7O12LAC+gWIC+InahiZ9satULpdLF6R2ka2D5n3c8+aX+nDTAV2cFqsXpjJqAuCHtfb7m5lrgJcLDbRpfN+umtAvtsNKiSTdc2GqLIa0aEuhvt5f0WHHBeDbKCYAzkhK13BdOThOkjR78XaT0wDwFRQTAGfs50dHTRZvLdTmfYyaADh7FBMAZ6x3l3BdlR4vSZq9OM/kNAB8AcUEwFn5+YQUWQxpybYibSooNzsOAC9HMQFwVnp1CdfVQxg1AeAeFBMAZ+2eCamyWgwt/bZYGxk1AXAWKCYAzlpyTJgmM2oCwA0oJgDc4ucTUmS1GFr2bbE27C0zOw4AL0UxAeAWPTqH6ZqWURPWNQFwZigmANzm5xNSZbMYWpHX/AwfAGgrigkAt0nqHKopQxMkMdcEwJmhmABwq59NSJHNYmjl9hLl7C41Ow4AL0MxAeBWidGhum5486jJ3xk1AdBGFBMAbnf3uOZRk9X5h5W9i1ETAK1HMQHgds2jJomSmGsCoG0oJgDaxc8mpCjAamjNjsP6Yudhs+MA8BIUEwDtIr5TiK4/OmrCXBMArUUxAdBuZo5PUaDVonU7S7V2B6MmAE6PYgKg3cR1CtENGcw1AdB6FBMA7eru8b1lGNIXu0p1oPyI2XEAeDiKCYB21d0eomFJUZKkJduKTE4DwNN1eDEpKCjQuHHjlJaWpkGDBumdd97p6AgAOtiF/WMlSYu3FJqcBICn6/BiYrPZNHv2bG3ZskWLFi3SL37xC9XU1HR0DAAdKLN/V0nS2h2HVVPfZHIaAJ6sw4tJ9+7dlZ6eLknq1q2bYmJiVFrKypCAL0vpGq4enUPV4HBq5fZis+MA8GBtLiYrVqzQFVdcobi4OBmGoQULFpywTVZWlpKTkxUcHKyRI0cqOzv7pPvKzc2Vw+FQYmJim4MD8B6GYejCfkcv52xlngmAU2tzMampqdHgwYOVlZV10vfnz5+vWbNm6aGHHtKGDRs0ePBgTZw4UUVFx/9jVFpaqqlTp+qFF174wePV19ersrLyuB8A3iczrflyztJtRXI4XSanAeCp2lxMJk2apIcffliTJ08+6ftPPPGEZsyYoenTpystLU3PPfecQkNDNWfOnJZt6uvrdfXVV+u+++7Teeed94PHe+SRR2S321t+GF0BvFNGcrQigm06XNOgjQVlZscB4KHcOsekoaFBubm5yszM/O4AFosyMzO1du1aSZLL5dItt9yiCRMm6Oabbz7tPu+//35VVFS0/BQUFLgzMoAOEmC1aFzf5lETLucAOBW3FpOSkhI5HA7FxsYe93psbKwOHTokSVq9erXmz5+vBQsWKD09Xenp6dq8efMp9xkUFKTIyMjjfgB4p2N353DbMIBTsXX0AUePHi2n09nRhwXgAcb16SqrxdD2omrtPVyrpM6hZkcC4GHcOmISExMjq9WqwsLj/zdUWFiobt26ufNQALyQPTRAI5KjJUmLtzJqAuBEbi0mgYGBGjZsmJYsWdLymtPp1JIlSzRq1Ch3HgqAl7rw2OUcigmAk2hzMamurtbGjRu1ceNGSdKuXbu0ceNG7d27V5I0a9Ysvfjii5o7d662bt2qu+66SzU1NZo+fbpbgwPwTplHl6fP3lWqiiONJqcB4GnaPMckJydH48ePb/nzrFmzJEnTpk3TK6+8ohtuuEHFxcV68MEHdejQIaWnp+uzzz47YUIsAP+UHBOmlK7hyi+q1vK8Yl05OM7sSAA8iOFyubxipaOsrCxlZWXJ4XAoLy9PFRUV3KEDeKlHPt2q55fv1FXpcfrHj4aYHQdAB6isrJTdbj/t93eHPyvnTM2cOVNbtmzR+vXrzY4C4CxddPRyztJtRWp0cJcegO94TTEB4DuGJEUpOixQlXVNytnNKrAAvkMxAdDhrBZD4/p2kSQt4e4cAP+FYgLAFMcu5yzeWigvmeoGoANQTACYYkyfLgq0WrT7cK12FNeYHQeAh6CYADBFeJBN5/buLInLOQC+QzEBYJpMVoEF8D0UEwCmmdCvuZjk7ilTaU2DyWkAeAKvKSZZWVlKS0tTRkaG2VEAuElCVKj6d4+U09W8pgkAeE0xYYE1wDcdu5yzZBuXcwB4UTEB4JuOPdRvRV6J6pscJqcBYDaKCQBTnRNvV5eIIFXXN+mLnaVmxwFgMooJAFNZLIYuPDoJltuGAVBMAJgus2UV2CJWgQX8HMUEgOnOT4lRkM2i/eVHtO1QldlxAJiIYgLAdCGBVo1JjZHE5RzA31FMAHiEC49ezvl8K+uZAP6MYgLAIxybALupoFxFVXUmpwFgFooJAI/QNTJYgxLskqRl24pNTgPALF5TTFiSHvB94/o2j5os304xAfyV1xQTlqQHfN/YPl0kSSvzitXkcJqcBoAZvKaYAPB96YmdZA8JUGVdkzbtKzc7DgATUEwAeAyrxWi5bXj5t1zOAfwRxQSARzl2OWd5HsUE8EcUEwAe5Vgx+Wp/hQ5X15ucBkBHo5gA8ChdI4PVv3ukXC5p5fYSs+MA6GAUEwAeZ1xfLucA/opiAsDjHLucsyKvWE4nTxsG/AnFBIDHGZoUpfAgmw7XNOjrAxVmxwHQgSgmADxOoM2i83p3lsRtw4C/oZgA8Egty9MzzwTwK15TTHhWDuBfLujTvNDahr1lqqhtNDkNgI7iNcWEZ+UA/iUhKlQpXcPldEmr8rltGPAXXlNMAPif71aBLTI5CYCOQjEB4LH+ez0Tl4vbhgF/QDEB4LEykqMVHGBRYWW9th2qMjvOSblcLq3IK9Yzy/K1vdAzMwLexGZ2AAA4leAAq0b16qyl3xZreV6x+nePNDtSi4Ympz7cdEAvrdzZUpr+9tm3yuzfVXeO7a2M5GiTEwLeiWICwKON7dOluZh8W6yfju1tdhxV1Dbq9ew9mrtmtwormx8yGBpo1eCETlq367AWby3S4q1FGtYjSj8d21sX9usqi8UwOTXgPSgmADzauL5dpY+2KGdPqarrmxQeZM4/Wy6XS0/9J1/PLd+h2gaHJCk2MkjTz++pG0ckyR4SoB3F1XpxxU69t2G/cveUaca8HPWJDdcLNw9XckyYKbkBb8McEwAeLTkmTD06h6rR4dIaE28bfm3dHj3xeZ5qGxzq1y1Cj183WCt/O0E/Hdtb9pAASVLvLuF6dMogrfrdeP10bG9FBNmUV1itO17NUU19k2nZAW9CMQHg8b67bdicVWDX7y7VHz/aIkn6zcS++vTeMZoyLEGBtpP/E9o1Mlj3Teqnxb8aqy4RQcorrNZv//UVdxYBrUAxAeDx/ruYdPSX+6GKOt312gY1OV26YnCc7h7XW4bRujkjsZHBevbHQ2WzGFr41UG9uHJnO6cFvB/FBIDHG9W7swKtFu0rO6KdJTUddtz6Jofuej1XJdX16tctQn+dck6rS8kxw5Oj9dAVaZKkRz/dptWsYgv8IIoJAI8XGmjTiJ7Nt98u68CnDf/vh1v05d5y2UMC9PzNwxQaeGYTb39ybg9NGZogp0v62RsbtK+s1s1JAd9BMQHgFTp6nsmb2Xv1ZvZeGYb05I1D1KPzmd9VYxiG/jx5oAbGR6qstlF3vbZBdY0ON6YFfIfXFBOeLgz4t7FHl6f/Yufhdv9S37C3TA998I0k6dcX920pRWcjOMCq534yTFGhAdq8v0IPfvD1We8T8EVeU0x4ujDg31K7hivOHqz6JqfW7jzcbscpqqrTXa/lqsHh1KSB3XT3OPct6pYQFaqnbhwqiyG9nbNP63eXum3fgK/wmmICwL8ZhtEyarK8neaZuFwuzZq/SYWV9UrtGq7Hrhvc5smupzM6NUY3ZCRJkh7+eIucTm4hBv4bxQSA1zh2SWVFO80zWbBxv1bllyjIZtFzNw9rt1VmZ13UR2GBVm3aV6EPNx1ol2MA3opiAsBrnJcSI5vF0M6SGu097N47W8prG/Twx1slSfdcmKreXcLduv//1iUiSHePT5Ek/fWzbTrSwERY4BiKCQCvERkcoKE9oiRJy/OK3LrvRz/dpsM1DeoTG64ZY3q5dd8nc9vonorvFKKDFXX65yoWXgOOoZgA8Crjjs4zef2LvWpyON2yz+xdpXprfYEk6S+TzznlUvPuFBxg1W8v6StJembZDhVV1bX7MQFvQDEB4FV+lJGkTqEB2naoSq+s2X3W+2tocur372+WJN04IlHDk6PPep+tdeXgOKUndlJtg0NPLMrrsOMCnoxiAsCrRIcF6r5L+kmS/v55ng5VnN1Iw4srd2p7UbU6hwXqd0f321EMw9ADl/eXJM3PKdCWA5UdenzAE1FMAHid64cnakhSJ9U0OPR/H2854/3sOVyjJ5dslyT94fL+6hQa6K6IrTasR7QuO6e7XC7pz59s4QnE8HsUEwBex2Ix9PDVA2UxpIWbD57RMvUul0sPfPCN6pucOj+ls65Oj2+HpK3zu0v6KdBq0er8w1r6rXsn9QLehmICwCsNiLPrlvN6SpIe+uDrNi9T/9FXB7Uir1iBNosevrrtTw12p6TOoZp+frIk6eGFW9Xopkm9gDeimADwWr+8KFVdI4K0+3Ctnl/e+ltuK4406k8fNV8CmjkuRT1jzvwBfe4yc0KKOocFamdxjV5ft8fsOIBpKCYAvFZEcIAeuDxNkpS1LF97Dtec9jMul0uPfrpVJdX16tUlTD8d1/5rlrRGZHCAfnlRH0nS3xdvV3ltg8mJAHNQTAB4tcsHddfolBg1NDn14Aff/ODk0Zr6Jv1i/ka9md28Zsmfrz5HQTZrR0U9rR9lJKpvbIQqjjTqH0cn5QL+hmICwKsZhqE/XTVAgVaLlucV67OvD510u7zCKl359Cp9sPGArBZDD16eplG9O3dw2h9ms1r0h6O3D7+6do92FFebnAjoeBQTAF6vV5dw3Tm2+ZLMHz/aour6puPef2/DPl319GrtKK5RbGSQ3rrjXN06uqcZUU9rTGoXTejXVU1Olx75ZKvZcYAO5zXFJCsrS2lpacrIyDA7CgAPNHN8ihKjQ3Sosq5lbZK6Rofuf+8rzXp7k440OjQ6JUYL7xmjjA5c3fVM/M+l/WWzGFq8tUir80vMjgN0KMPlZav5VFZWym63q6KiQpGRkWbHAeBBlm4r0vRX1stqMfTMj4fqH4u3a8vBShmGdO+Fqfr5hFRZLebdFtwW//vhN3plzW716xahhfeM8ZrcwKm09vvba0ZMAOB0xvfrqokDYuVwunTnq7nacrBSncMCNe/WEfpFZh+v+nK/98JU2UOanwn03PIdZscBOgzFBIBPefCKAQoJaL7TZniPKC28Z4zGpHYxOVXbRYUF6veXNU+EfeLzPOXsLjU5EdAxuJQDwOds2Fum/MJqTR4arwCr9/7/y+Vy6ZfzN2rBxgOKswdr4T1jFBXW8c/zAdyBSzkA/NbQpChdn5Ho1aVEar4V+uHJ56hnTJgOVNTpN+9u4iF/8HnefdYCgI8LD7Lp6ZuGKNBm0eKtRZqzerfZkYB2RTEBAA83IM6uB47ON3n0063aVFBubiCgHVFMAMAL/OTcHpo0sJsaHS7NfGOD9pXVmh0JaBcUEwDwAoZh6NEpg9Sjc6j2lR3Rtc+uVV5hldmxALejmACAl7CHBOitO85VatdwHaqs03XPrVXunjKzYwFuRTEBAC/S3R6id346SkOTOqniSKN+/NI6Lf22yOxYgNtQTADAy3QKDdRrt4/UuL5dVNfo1Iy5OXr/y31mxwLcgmICAF4oNNCmF6cO1+Qh8WpyuvTL+Zv0woodrHMCr0cxAQAvFWC16PHrBuv20T0lSX/5ZJseXrhVTiflBN6LYgIAXsxiMfSHy9P0+0ub1zn556pdunf+RtU3OUxOBpwZigkA+IAZF/TS7BvSFWA19NGmA7p9bo4aHU6zYwFtRjEBAB9x9ZB4zbklQ6GBVq3cXqLHF+WZHQloM4oJAPiQMald9Ni1gyVJzy3foaXbuJUY3oViAgA+5rJB3TV1VA9J0qy3N+pgxRGTEwGtRzEBAB/0P5f214C4SJXVNuqeN79UE/NN4CUoJgDgg4IDrMq6aajCg2xav7tMT3zOfBN4B4oJAPio5JgwPTrlHEnSM8t2aGNBubmBgFbwmmKSlZWltLQ0ZWRkmB0FALzG5YPiNHlIvCTpsX9vMzkNcHqGy8vWL66srJTdbldFRYUiIyPNjgMAHq+gtFYTHl+mRodLr902UqNTY8yOBD/U2u9vrxkxAQCcmcToUP14ZPNdOo/9exvP04FHo5gAgB+YOT5FoYFWbdpXoX9/c8jsOMApUUwAwA90iQjSbUcf9vf/FuXJwYP+4KEoJgDgJ2Zc0EudQgOUX1St9zbsMzsOcFIUEwDwE5HBAbprbG9J0uzF23kCMTwSxQQA/Mi085LVLTJY+8uP6K3sArPjACegmACAHwkOsGrmhBRJUtbSfNU1MmoCz0IxAQA/c8PwRMV3ClFRVb1eW7fH7DjAcSgmAOBnAm0W3XNh86jJs8t2qKa+yeREwHcoJgDgh64ZmqAenUN1uKZBc9fuNjsO0IJiAgB+KMBq0b0XpkqSXlixU1V1jSYnAppRTADAT12VHq/eXcJUXtuoOat2t/nzZTUN3HIMt7OZHQAAYA6rxdAvMvvo529+qRdX7tSkc7qpT2zEKbdvdDj1Ts4+rdt5WBsLyrW3tFbhQTY9fv1gTRzQrQOTw5cxYgIAfuyyc7orIzlK1fVNmvrPbO0rqz3pdocq6nTjC+v0P+9v1oebDmhvafN21fVNuvPVXP1j8XY5WeYebkAxAQA/ZrEYenHqcKV2DdehyjpN/We2DlfXH7fN6vwSXf7USuXsKVNEkE33XpiqV28boQ0PXKRbzkuWJP19cZ5mvrGBdVFw1gyXlz3/urKyUna7XRUVFYqMjDQ7DgD4hIMVRzTlmTU6UFGnQQl23TMhVVsOVuqrfRX6z7ZCOV1S/+6RevbHQ5UcE3bcZ99eX6A/LPhaDQ6nZozpqd9flmbS3wKerLXf3xQTAIAkKb+oWtc9t0ZltSfeoXPD8ET98aoBCg6wnvSzn28p1Ix5OTIM6e07RykjObq948LLUEwAAG22qaBcM9/YoJAAqwbG2zUgLlLDekRpSFLUaT/7m3c26Z3cferROVSf3jtGoYHcX4HvUEwAAB2qsq5Rl/x9hQ5U1GnqqB7601UDzY4ED9La728mvwIA3CIyOEB/vXaQJGne2j1atb3E5ETwRhQTAIDbjEntop+cmyRJ+tU7G1VW02ByIngbigkAwK1+f2maenUJU2Flve577yt52YwBmIxiAgBwq5BAq5780RAFWA39+5tCzV9fYHYkeBGKCQDA7QbG2/WbiX0lSX/8aIu2HKg0ORG8BcUEANAubh/dS+endNaRRoeuf36tlucVmx0JXoBiAgBoFxaLoWduGqZze0Wrur5Jt76yXq+u28OcE/wgigkAoN3YQwM079aRmjI0QQ6nSw8s+FqXPblKb68v4Lk6OCkWWAMAtDuXy6Vnl+/QPxZvV32TU5IUHRao20b31NRRPRQRHGByQrQ3Vn4FAHicspoGzc8p0Ktr92h/+RFJkj0kQD8bn6Lbx/SUYRgmJ0R78blikpWVpaysLDkcDuXl5VFMAMCLNTmc+uirA3r6P/naUVwjSbp+eIL+Mvkc2azMMvBFPldMjmHEBAB8h8Pp0mvr9uiPH30jp0u6sF9XPX3TUIUEnvwpxvBePCsHAODxrBZD085L1vM3D1eQzaIl24o0Y16OGh1Os6PBJBQTAIDpLkqL1eu3j1RooFWr8kv0+/c3c1uxn6KYAAA8wvDkaD190xBZDOntnH3KWppvdiSYgGICAPAYE/rF6o9XDpAk/b9FeXpp5U6TE6GjUUwAAB7l5lHJuntcb0nSwwu36q+fbeOyjh+hmAAAPM5vJvbV7y7pJ0l6dtkO3fzPbC34cr+q65tMTob2ZjM7AAAA32cYhu4a11vRYQG6/73NWpVfolX5JZKk4ACLwoMCNLxHlKYMS9C4vl0UwNonPoN1TAAAHm1HcbU++HK/Ptx0QLsP157wflJ0qF67baSSOoeakA6txQJrAACf4nK5VF7bqOr6JhVX1+uTrw7q/S/363BNgxKiQvT2naMU1ynE7Jg4BYoJAMDnFVXW6frn12r34Vr1jAnTOz8dpZjwILNj4SRY+RUA4PO6Rgbr9RnnKr5TiHaV1Oj+91iYzdtRTAAAXi2+U4hemjZcAVZDn28p1AcbD5gdCWeBYgIA8Hr9u0fq5xNSJUkPffiNiqrqTE6EM0UxAQD4hLvG9daAuEhVHGnU/3BJx2tRTAAAPiHAatHj1w9WoNWixVuL9Nb6ArMj4QxQTAAAPqNft0j9emIfSdKfPtqiXSU1JidCW1FMAAA+5fbRvTSqV2cdaXTo7tc3qLy2wexIaAOKCQDAp1gshh6/frA6hwVq68FK3fTiFyqtoZx4C4oJAMDnxHUK0RszzlVMeKC2HKzUdc+t0df7K8yOhVagmAAAfFLfbhF6645Rio0M0o7iGl2VtVqPL/pWjQ6n2dHwAygmAACfldI1XJ/cM0aXDeouh9Olp/6Tr+ufX6uC0hMfBgjPQDEBAPi0zuFByrppqJ6+aYgigm36cm+5Ln1ypdbtPGx2NJwExQQA4BcuHxSnT+4ZoyFJnVRV16Spc7K16JtDZsfC91BMAAB+IzE6VG/OOFeZ/WPV0OTUT1/L1Surd7FKrAehmAAA/EpwgFXP/WSobhieKKdL+t+Ptuh/3v9aVXWNZkeDKCYAAD9ks1r06JRzdP+kfjIM6c3svRr32DL9c9UuVVJQTGW4vGz8qrKyUna7XRUVFYqMjDQ7DgDAyy3PK9YfP/xGO48uXx8SYNWUYfH6zcR+socEmJzOd7T2+5tiAgDwe40Op97OKdArq3dre1G1JKm7PViPXz9Y5/WOMTmdb6CYAADQRi6XS2t3HNb972/WnsO1CrRZ9MbtIzU8OdrsaF6vtd/fzDEBAOAowzB0XkqMPr13jDL7d1VDk1Mz5uVoN08p7jAUEwAAvic00KYnbxyiQQl2ldU2asa8HNU2NJkdyy9QTAAAOInQQJtemjZcXSOCtL2oWg8s+MbsSH6BYgIAwCl0jQjWkzcOkcWQ/rVhn+at3W12JJ9HMQEA4Aec26uzfnVxX0nSgx98o7ey95qcyLdRTAAAOI27x/XWref3lCTd995m/fbdTSquqjc5lW+imAAAcBqGYeiBy/vrzgt6SZLeztmnC/62VH/86BsVVtaZnM63UEwAAGgFwzB0/6X99a+7ztPgxE460ujQy6t3K/Px5Zq/fi8PAnQTFlgDAKCNXC6XVm4v0eOLvtWmfRWSpMsGdddj1w5SaKDN5HSeiQXWAABoJ4Zh6II+XfTe3efr/kn9ZLMYWvjVQV3zzBoWYztLFBMAAM6Q1WLozrG99eYd5yomPEjbDlXpiqdXaem2IrOjeS2KCQAAZykjOVof/3y0hiZ1UlVdk26du14vrdzJvJMzQDEBAMANutmD9dYdo3TjiES5XNLDC7fqH0u2mx3L61BMAABwk0CbRX+ZfI7un9RPkjR78Xa9vHqXyam8C8UEAAA3MozmeSezLuojSfrTx1v06eaDJqfyHhQTAADawc8npGjqqB5yuaRfzN+o5XnFZkfyChQTAADagWEYevDyNGX276r6Jqemv5ytv322jduJT4MF1gAAaEf1TQ49sOBrvZ2zr+W1rhFBuqBPF00/P1kD4uwmpus4Hr3A2uTJkxUVFaVrr73WjMMDANBhgmxW/XXKID114xCNSY2R1WKoqKpe7+bu02VPrtIv3vpSRTxvp4UpIybLli1TVVWV5s6dq3fffbdNn2XEBADgzWobmrSxoFxvfLFXCzcflMslhQfZNOuiPpp2XrKsFsPsiO3Co0dMxo0bp4iICDMODQCAqUIDbTqvd4yevmmoPph5vgYndlJ1fZP+9PEWTXl2jfKLqs2OaKo2F5MVK1boiiuuUFxcnAzD0IIFC07YJisrS8nJyQoODtbIkSOVnZ3tjqwAAPiUQQmd9N5d5+nhqwcqIsimjQXluvLpVXo3d5/frhrb5mJSU1OjwYMHKysr66Tvz58/X7NmzdJDDz2kDRs2aPDgwZo4caKKis7suQH19fWqrKw87gcAAF9htRj6ybk9tGjWBTqvd2fVNjj063c26Y5Xc7XlgP9957W5mEyaNEkPP/ywJk+efNL3n3jiCc2YMUPTp09XWlqannvuOYWGhmrOnDlnFPCRRx6R3W5v+UlMTDyj/QAA4Mm620P06m0j9ZuJfRVgNfT5lkJd+uRKXfqPlXphxQ5V1TWaHbFDuHWOSUNDg3Jzc5WZmfndASwWZWZmau3atWe0z/vvv18VFRUtPwUFBe6KCwCAR7FaDM0cn6IPfzZalw/qLpvF0JaDlfrLJ9t0/qP/0ZxVu9TocJods13Z3LmzkpISORwOxcbGHvd6bGystm3b1vLnzMxMbdq0STU1NUpISNA777yjUaNGnXSfQUFBCgoKcmdMAAA8Wv/ukXr6pqEqrWnQZ18f0pzVu5RfVK0/fbxFc1bv0szxKbpmaLyCbFazo7qdW4tJay1evNiMwwIA4FWiwwJ108gk3ZCRqPnrC/TE599qX9kR3f/eZj21ZLtmXdxXk4fE+9Qtxm69lBMTEyOr1arCwsLjXi8sLFS3bt3ceSgAAPyG1WLoppFJWvnbCXrg8jTFRgbpQEWdfv3OJl325Ep9svmgHE7fuIvHrcUkMDBQw4YN05IlS1peczqdWrJkySkv1QAAgNYJCbTqttE9tfw343XfpH6KDLZp26Eq3f36Bl0ye4U++/qQ199m3OZLOdXV1crPz2/5865du7Rx40ZFR0crKSlJs2bN0rRp0zR8+HCNGDFCs2fPVk1NjaZPn+7W4AAA+KvgAKt+Ora3fpSRqDmrdmnu2j3aXlStn76Wq4HxkfrdJf00JrWL2THPSJuXpF+2bJnGjx9/wuvTpk3TK6+8Ikl6+umn9dhjj+nQoUNKT0/Xk08+qZEjR7olMEvSAwBwvIojjXphxQ69vHq3ahsckqSL0mL1f1cNVDd7sMnpmrX2+5unCwMA4CMOV9frqf/k69V1e+RwutQpNED3XdJP1w5LkM1qylNoWvhcMcnKylJWVpYcDofy8vIoJgAAnEJeYZV+9fYmbd5fIUnq0TlUd43trWuGJijQZk5B8blicgwjJgAAnF5Dk1Pz1u5W1tJ8ldU2rxqbGB2i307sp8sHdZdhdOwtxhQTAACgmvomvZm9V8+v2KniqnpJ0qAEu351cV9dkBrTYQWFYgIAAFrUNjTpxRW79MKKHao5OkF2VK/OmnVxH2UkR7f78SkmAADgBCXV9Xp22Q69unaPGo4+d2dUr8767SV9NSQpqt2OSzEBAACntL/8iJ7+T77ezS1Qo6O5ClycFqtfT+yrPrERbj8exQQAAJzW/vIjmv15nv61YZ+cLskwpL9NGaTrhie69Tit/f4296ZmAABgqvhOIXrsusFa9MsLNGlgNwXZLKauGmvK04UBAIBnSekaoWd/MkyFlXWKjTRvtVivGTHJyspSWlqaMjIyzI4CAIDPMrOUSMwxAQAAHYA5JgAAwOtQTAAAgMegmAAAAI9BMQEAAB6DYgIAADwGxQQAAHgMigkAAPAYFBMAAOAxvKaYsPIrAAC+j5VfAQBAu2PlVwAA4HUoJgAAwGPYzA7QVseuPFVWVpqcBAAAtNax7+3TzSDxumJSVVUlSUpMTDQ5CQAAaKuqqirZ7fZTvu91k1+dTqf69Omj3NxcGYbRqs9kZGRo/fr1P7hNZWWlEhMTVVBQwKTao1rzezNTR+drr+O5a79ns58z+WxbP8N5eGY4DzvmeJyH32mv89DlcqmqqkpxcXGyWE49k8TrRkwsFosCAwN/sG19n9VqbfUvNzIykn8Qj2rL780MHZ2vvY7nrv2ezX7O5LNt/Qzn4ZnhPOyY43Eenqg9zsPWfHd75eTXmTNntuv2aObpv7eOztdex3PXfs9mP2fyWc7DjuHpvzfOQ/fth/OwmdddymkvrI8CmI/zEDCf2eehV46YtIegoCA99NBDCgoKMjsK4Lc4DwHzmX0eMmICAAA8BiMmAADAY1BMAACAx6CYAAAAj0ExAQAAHoNiAgAAPAbFpJU+/vhj9e3bV6mpqXrppZfMjgP4pcmTJysqKkrXXnut2VEAv1RQUKBx48YpLS1NgwYN0jvvvOP2Y3C7cCs0NTUpLS1NS5culd1u17Bhw7RmzRp17tzZ7GiAX1m2bJmqqqo0d+5cvfvuu2bHAfzOwYMHVVhYqPT0dB06dEjDhg1TXl6ewsLC3HYMRkxaITs7WwMGDFB8fLzCw8M1adIkLVq0yOxYgN8ZN26cIiIizI4B+K3u3bsrPT1dktStWzfFxMSotLTUrcfwi2KyYsUKXXHFFYqLi5NhGFqwYMEJ22RlZSk5OVnBwcEaOXKksrOzW947cOCA4uPjW/4cHx+v/fv3d0R0wGec7XkI4Oy58zzMzc2Vw+FQYmKiWzP6RTGpqanR4MGDlZWVddL358+fr1mzZumhhx7Shg0bNHjwYE2cOFFFRUUdnBTwXZyHgPncdR6WlpZq6tSpeuGFF9wf0uVnJLnef//9414bMWKEa+bMmS1/djgcrri4ONcjjzzicrlcrtWrV7uuvvrqlvfvvfde1+uvv94heQFfdCbn4TFLly51TZkypSNiAj7tTM/Duro615gxY1zz5s1rl1x+MWLyQxoaGpSbm6vMzMyW1ywWizIzM7V27VpJ0ogRI/T1119r//79qq6u1qeffqqJEyeaFRnwOa05DwG0r9achy6XS7fccosmTJigm2++uV1y+H0xKSkpkcPhUGxs7HGvx8bG6tChQ5Ikm82mxx9/XOPHj1d6erp+9atfcUcO4EatOQ8lKTMzU9ddd50++eQTJSQkUFoAN2rNebh69WrNnz9fCxYsUHp6utLT07V582a35rC5dW8+7Morr9SVV15pdgzAry1evNjsCIBfGz16tJxOZ7sew+9HTGJiYmS1WlVYWHjc64WFherWrZtJqQD/wnkImM9TzkO/LyaBgYEaNmyYlixZ0vKa0+nUkiVLNGrUKBOTAf6D8xAwn6ech35xKae6ulr5+fktf961a5c2btyo6OhoJSUladasWZo2bZqGDx+uESNGaPbs2aqpqdH06dNNTA34Fs5DwHxecR62y70+Hmbp0qUuSSf8TJs2rWWbp556ypWUlOQKDAx0jRgxwrVu3TrzAgM+iPMQMJ83nIc8KwcAAHgMv59jAgAAPAfFBAAAeAyKCQAA8BgUEwAA4DEoJgAAwGNQTAAAgMegmAAAAI9BMQEAAB6DYgIAADwGxQQAAHgMigkAAPAYFBMAAOAx/j+rTB1+lfuv3QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.loglog(train_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCANTRA - DeepUnrolling SCA for Neural networks TRAining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to define a surrogate loss using a general purpose second order approximations and the gradient of the feedforward network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCANTRALayer(nn.Module):\n",
    "    def __init__(self, model, lambda_ = 0.1, tau = 1, gamma = 0.9):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialization of the learnable parameters\n",
    "        self.lambda_ = nn.Parameter(torch.ones(1)*lambda_, requires_grad = True)\n",
    "        self.tau = nn.Parameter(torch.ones(1)*tau, requires_grad = True)\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        self.B = []\n",
    "        for _, p in model.named_parameters():\n",
    "            self.B.append(nn.Parameter(torch.randn(p.shape[0]), requires_grad = True))\n",
    "\n",
    "        self.params = nn.ParameterList(self.B + [self.lambda_, self.tau])\n",
    "\n",
    "\n",
    "    def forward(self, model):\n",
    "        for i, (_, p) in enumerate(model.named_parameters()):\n",
    "            K = p.grad\n",
    "            print(K)\n",
    "            # Local optimization step\n",
    "            if len(p.shape) == 1:\n",
    "                I = torch.ones(self.B[i].shape[0])\n",
    "                H = self.B[i]**2 + self.tau*I\n",
    "                M = 1/((2*self.lambda_ + self.tau)*I + H)\n",
    "                \n",
    "            else:\n",
    "                I = self.tau*torch.eye(self.B[i].shape[0])\n",
    "                H = torch.outer(self.B[i],self.B[i]) + self.tau*I\n",
    "                M = torch.linalg.inv((2*self.lambda_ + self.tau)*I + H)\n",
    "\n",
    "            w_hat = M @ (H @ p - K)\n",
    "            #p_0 = p\n",
    "\n",
    "            with torch.no_grad():\n",
    "                p.copy_(p + self.gamma*(w_hat - p))\n",
    "\n",
    "            #print(torch.linalg.norm(p - p_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCANTRANet(nn.Module):\n",
    "    def __init__(self, model, T = 10, lambda_ = 0.1, tau = 25, gamma = 0.8):\n",
    "        super(SCANTRANet, self).__init__()\n",
    "        \n",
    "        # Number of iterations <-> number of layers\n",
    "        self.T = T\n",
    "        \n",
    "        # Initialization of the learnable parameters\n",
    "        self.lambda_0 = torch.ones(T)*lambda_\n",
    "        self.tau_0 = torch.ones(T)*tau\n",
    "        self.gamma_0 = torch.ones(T)*gamma\n",
    "\n",
    "        for i in range(self.T):\n",
    "            self.gamma_0[i] *= 0.99**i\n",
    "            \n",
    "        # Defining the layers\n",
    "        self.SCANTRA_layers = nn.ModuleList([SCANTRALayer(model,\n",
    "                                                          self.lambda_0[i], \n",
    "                                                          self.tau_0[i], \n",
    "                                                          self.gamma_0[i]\n",
    "                                                          ) for i in range(self.T)])\n",
    "        \n",
    "        # Optimizer of the neural optimizer\n",
    "        self.optimizer = torch.optim.Adam(params=self.parameters(), lr=1e-1, weight_decay = 5e-4)\n",
    "        \n",
    "    def step(self, model, criterion, epoch, X_train_tensor, y_train_tensor):\n",
    "        \n",
    "        self.SCANTRA_layers[epoch].forward(model)\n",
    "        self.source = model\n",
    "        \n",
    "        # Compute loss\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        \n",
    "        # Zero gradients for optimizer parameters\n",
    "        self.zero_grad()\n",
    "\n",
    "        # Compute gradients of loss with respect to optimizer parameters\n",
    "        loss.backward(retain_graph=True)\n",
    "\n",
    "        # Update optimizer parameters\n",
    "        self.optimizer.step()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(13, 30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30, 1)\n",
    ")\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = SCANTRANet(model, T = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is: how do I train at the same time the network and the optimizer? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "\n",
    "for epoch in range(1):\n",
    "    # Forward pass\n",
    "    model.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    \n",
    "    # Our beautiful neural optimizer\n",
    "    optimizer.step(model, criterion, epoch, X_train_tensor, y_train_tensor)\n",
    "    #optimizer.transfer(model)\n",
    "    \n",
    "    # Store loss value\n",
    "    train_losses.append(loss.item())\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{100}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test_tensor)\n",
    "        test_loss = criterion(test_outputs, y_test_tensor)\n",
    "        print(f'Test Loss: {test_loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(train_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "'''\n",
    "import torch, numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SEED = 4200\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "'''\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Boston dataset\n",
    "boston = load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert data to TensorFlow tensors\n",
    "X_train_tensor = tf.constant(X_train, dtype=tf.float32)\n",
    "y_train_tensor = tf.constant(y_train, dtype=tf.float32)\n",
    "X_test_tensor = tf.constant(X_test, dtype=tf.float32)\n",
    "y_test_tensor = tf.constant(y_test, dtype=tf.float32)\n",
    "\n",
    "# Reshape y tensors to match model output shape\n",
    "y_train_tensor = tf.reshape(y_train_tensor, shape=(-1, 1))\n",
    "y_test_tensor = tf.reshape(y_test_tensor, shape=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation='relu', input_shape=(13,)),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-1, decay=5e-4)\n",
    "\n",
    "\n",
    "# Define the loss function\n",
    "criterion = tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 59.6706\n",
      "Epoch [20/100], Loss: 35.7853\n",
      "Epoch [30/100], Loss: 21.7919\n",
      "Epoch [40/100], Loss: 14.4500\n",
      "Epoch [50/100], Loss: 11.1501\n",
      "Epoch [60/100], Loss: 9.9278\n",
      "Epoch [70/100], Loss: 8.8891\n",
      "Epoch [80/100], Loss: 8.0819\n",
      "Epoch [90/100], Loss: 7.4705\n",
      "Epoch [100/100], Loss: 6.9707\n",
      "Test Loss: 14.0148\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    # Forward pass\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(y_train_tensor, outputs)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    # Store loss value\n",
    "    train_losses.append(loss.numpy())\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{100}], Loss: {loss.numpy():.4f}')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_outputs = model(X_test_tensor)\n",
    "test_loss = criterion(y_test_tensor, test_outputs)\n",
    "print(f'Test Loss: {test_loss.numpy():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1eb3e630730>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAAGhCAYAAABVk3+7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA6FklEQVR4nO3deXhU5cH+8fvMTPZlQghkh7BDEEgIAcENEBdUFERFaxW1tVWx1aJvf9ra2sXWtrYWl4hbqfrWBVHBKtUKEUQWDQSCYFgCBgiBJISQTBKyzszvj0jUV8Ask5yZyfdzXbl6ZZZzbrDHc/uc5zzHcLvdbgEAAHgBi9kBAAAATqCYAAAAr0ExAQAAXoNiAgAAvAbFBAAAeA2KCQAA8BoUEwAA4DVsZgdoL5fLpUOHDikiIkKGYZgdBwAAtIHb7VZ1dbUSEhJksZx6XMTnismhQ4eUnJxsdgwAANABRUVFSkpKOuX7PldMIiIiJLX8wSIjI01OAwAA2sLhcCg5Obn1PH4qPldMTly+iYyMpJgAAOBjvmsaBpNfAQCA16CYAAAAr0ExAQAAXsNniklWVpZSU1OVmZlpdhQAANBFDLfb7TY7RHs4HA7Z7XZVVVUx+RUAAB/R1vO3z4yYAAAA/0cxAQAAXoNiAgAAvAbFBAAAeA2KCQAA8BoUEwAA4DUoJgAAwGtQTAAAgNegmAAAAK9BMQEAAF7DZ4oJz8oBAMD/8awcAADQ5XhWDgAA8DkUEwAA4DUoJgAAwGtQTAAAgNegmAAAAK9BMQEAAF6DYgIAALwGxQQAAHgNigkAAPAaFBMAAOA1KCYAAMBr+Ewx4SF+AAD4Px7iBwAAulxbz9+2bszkUQcrjiui2bPxw4Jsig4L9Og2AQBA2/lsMbn4sY9lCQr1+HbH9e+lmemJunRUvHpRUgAA6FY+W0yCAyyyBlg9us36Zqc27T+mTfuP6bfvfK7zhvbVrPREnT+ir4I9vC8AAPBtzDH5mlJHvd7ZekhLtxTr80OO1tcjgmy6+Iw4zUxP1JkDe8tqMTy6XwAA/F1bz98Uk1MoKK3WsrxiLdtySMWVda2vx0YG6Yq0RF2RlqDU+EgZBiUFAIDvQjHxEJfLrU37j2lZXrGWf3ZYVXVNre8NjQ3XzPREXZGWqMSokC7PAgCAr6KYdIGGZqdW7zqit/OKtXJHmRqbXa3vjR8QrVnpibrkjHjZQwO6NRcAAN6OYtLFquqa9N/tJVq6pVifFB7Vib/FQKtFU4b30az0RE0exqRZAAAkikm3OlxVp3/ntUya3VlS3fp6RLBNl46K18z0RI1PiZaFSbMAgB6KYmKSnSUOLdtySG/nFetwVX3r6wn2YF2elqhZ6YkaFhdhYkIAALofxcRkLpdbnxZW6O28Yi3fdljV9c2t7w2Pi9Cs9ERdnpageDuTZgEA/o9i4kXqm5xatbNMy/KKtWrnETU6WybNGoZ05oDempWeqItHxSkymEmzAAD/RDHxUlXHm/Sf7Ye1dEuxcgorWl8PtFk0bURfzUxrmTQbaPOZBz8DAPCdKCY+4OCx4/r31kNaurlYBWU1ra/bQwJ06eh4zUpPVEa/XkyaBQD4PIqJD3G73co/7NDbeS2TZksdDa3vJUaFaGZ6gmamJWpILJNmAQC+ye+KSVZWlrKysuR0OrV7926/KiZf53S59ckXR7VsS7He216imoavJs2OTIjUrPREzRiToNjIYBNTAgDQPn5XTE7wxxGTU6lvcmrljlIt23JIq3eVqdnV8o/KYkiTBsVoZnqiLhoZqwgmzQIAvBzFxM9U1DZq+bbDentLsTbtP9b6epDNogtSYzUzLVHnDu3DpFkAgFeimPixA0eP6+28Yi3NK9YXR2pbX+8VGqDLRidoZnqCxvbrxZOPAQBeg2LSA7jdbm0vdmjplmL9e+shldd8NWm2X3SoZqYl6Ir0RA3qE25iSgAAKCY9TrPTpfV7WybNvv95iY43OlvfG51k18y0lkmzfSKCTEwJAOipKCY92PHGZq3IL9XbeYf00e4jcn5t0uzZQ/poVnqCLkyNU1iQzeSkAICegmICSVJ5TYOWf3ZYy/KKteVAZevrIQFWXTgyVjPTE3XO4BjZrEyaBQB0HYoJvmVfea2W5RXr7bxDKiz/atJs77BAzRiToJnpiRqTZGfSLADA4ygmOCW3262tB6u0bEux3tl6SEdrG1vfS+kdqpnpiZqZlqiUmDATUwIA/AnFBG3S5HRp7Z5yLdtSrA8+L1Vd01eTZjP699KfZ4/S4L4shQ8A6ByKCdqttqFZH+SXaOmWQ1pbcEQud8sDBZ+fO06ZKdFmxwMA+DCKCTqlpKped7ycq80HKhVos2jBnDRdMire7FgAAB/V1vM3t2LgpOLswXr5h2fqwtRYNTa7NO+VzfrH2kKzYwEA/BzFBKcUEmjVwu9n6IYz+8vtln7/br4eejdfLpdPDbIBAHwIxQSnZbUY+t0VI/X/Lh4uSXp+baF+8toW1X9tkiwAAJ5CMcF3MgxDt08epAVz0hRgNbT8s8O6cVGOqo43mR0NAOBnKCZos5npiXrx5vGKCLIpp7BCVz29XsWVdWbHAgD4EYoJ2mXS4Bi9fttExUUGq6CsRrOy1in/kMPsWAAAP0ExQbuNiI/UW3dM0tDYcJVVN+iaZzZobUG52bEAAH6AYoIOSYgK0ZLbJunMgdGqaWjWTf/M0VubD5odCwDg4ygm6DB7SIBevGW8ZoxJULPLrfmvb1XWqj3ysTX7AABexGeKSVZWllJTU5WZmWl2FHxNkM2qx+ak6cfnDpQkPfLfXXpg2XY1O10mJwMA+CKWpIfHvLCuUL99N19utzRtRF89fl26QgNtZscCAHgBlqRHt7vprAFaeP1YBdksWrmjTNc996mO1jSYHQsA4EMoJvCoi8+I18s/nKCo0ABtLarU7IXrta+81uxYAAAfQTGBx41Lidabt09SUq8Q7Tt6XLMXrldeUaXZsQAAPoBigi4xqE+43rpjks5IjNTR2kZd++wGrcwvNTsWAMDLUUzQZfpGBOu1H03UeUP7qL7JpR/97ya9/Ol+s2MBALwYxQRdKjzIpufnjtPVGUlyuaVfLt2uv/53F2udAABOimKCLhdgtegvV43WXecPkSQ9uWqP7lmyVY3NrHUCAPgmigm6hWEY+tkFQ/Xn2aNktRh6a3OxfvDiRlXXN5kdDQDgRSgm6FZzMvvp+bnjFBpo1ccF5brmmU9U6qg3OxYAwEtQTNDtpgzrq9d+dKZiwgO147BDVz61XgWl1WbHAgB4AYoJTDE6KUpv3X6WBsaEqbiyTrMXrtenXxw1OxYAwGQUE5imX+9QvXH7JI3tFyVHfbNu+EeOln922OxYAAATUUxgquiwQL1y65m6MDVWjU6X5r2yWc9//IXZsQAAJqGYwHTBAVYt/H6GbpzYX5L00PId+t07+XK5WOsEAHoaigm8gtVi6LeXj9R904dLkhatK9Sdr25WfZPT5GQAgO5EMYHXMAxDt503SI9dm6YAq6H/bCvRjf/IUeXxRrOjAQC6CcUEXueKtES9eMt4RQTZlLOvQlc9vUEHjx03OxYAoBtQTOCVJg2K0ZLbJyouMlh7ymo066n1+vxQldmxAABdjGICrzU8LlJL503SsNgIHalu0DVPb9Ca3UfMjgUA6EIUE3i1eHuIXr9tos4cGK3aRqdueWGj3sg9aHYsAEAXoZjA69lDAvTiLeN1+ZgENbvcunfJVj35YYHcbm4nBgB/QzGBTwiyWbVgTpp+fN5ASdJfP9itXy7bzlonAOBnKCbwGRaLofunj9BvLx8pw5Be+fSAnmWVWADwKxQT+Jy5k1L0+yvOkCQ98t9d+oSH/wGA36CYwCddP6GfrkxPlNPl1k9e3aKy6nqzIwEAPIBiAp9kGIYemnWGhsaG60h1g3766hY1O11mxwIAdBLFBD4rNNCmhd/PUFigVZ98UaFHV+w2OxIAoJMoJvBpg/qE60+zR0uSnlq9V9k7Sk1OBADoDJ8pJllZWUpNTVVmZqbZUeBlZoxJ0E2TUiRJP1ucp6IKnqsDAL7KcPvYKlUOh0N2u11VVVWKjIw0Ow68RGOzS9c8s0F5RZUalWjXG7dPVJDNanYsAMCX2nr+9pkRE+B0Am0WZV0/VlGhAdpWXKXfv5tvdiQAQAdQTOA3EqNCtGBOmgxD+tcnB7RsS7HZkQAA7UQxgV+ZPKyv7pwyWJJ0/1vbVFBabXIiAEB7UEzgd+6eNlSTBvVWXZNTt7+8WbUNzWZHAgC0EcUEfsdqMfT4demKjQzSnrIa3f/WNp5EDAA+gmICvxQTHqQnvzdWVouhf289pH99esDsSACANqCYwG9lpkTrvouHS5J+/06+thZVmhsIAPCdKCbwaz88Z4AuTI1Vo9OlO17erMrjjWZHAgCcBsUEfs0wDD1y9Rj17x2q4so6zX99q1wu5psAgLeimMDv2UMC9NT1YxVos+jDnWVa+NFesyMBAE6BYoIeYWSCXb+/YqQk6W8f7NL6veUmJwIAnAzFBD3GNeOSdVVGklxu6aevblGpo97sSACA/4Nigh7DMAz9/oozNDwuQuU1jfrJK1vU7HSZHQsA8DUUE/QoIYFWPXX9WIUH2ZSzr0KPfLDL7EgAgK+hmKDHGdgnXH+5arQk6ZmPvtAHn5eYnAgAcALFBD3SJaPidctZAyRJ9yzZqgNHj5ucqHPqm5yqqGWNFgC+j2KCHuu+6cM1tl+UquubdfvLuapvcpodqUN2HHZo2qMfadxDK3TLCxu1Ir+UuTMAfJbh9rGnmzkcDtntdlVVVSkyMtLsOPBxhyrrdNkTa1VR26jrxvfTw1eOMjtSu3zweYnuXpyn443fLFWxkUGaMy5Z12QmK6lXqEnpAOArbT1/M2KCHi0hKkQL5qTJMKRXcw7ozdyDZkdqE7fbradW79GP/5Wr441OnTW4t96ed5Z+fO5ARYcFqtTRoMc/3KNz/rJKN/0zR//9vERNjKIA8AGMmACSFqzcrQUrCxQcYNGyeWdpeJz3/n+rvsmp+978TMvyDkmSbpzYX7+6LFUB1pb/zmhodmpFfqlezTmgdXuOtn6vb0SQrhmXrDmZyUqOZhQFQPdq6/mbYgJIcrrcuumfOfq4oFwDY8L075+crfAgm9mxvqXMUa8f/W+u8ooqZbUY+s3lI3XDmf1P+fl95bV6bWOR3sgtUnlNy+RYw5DOGdJH3xvfT+eP6NtaaACgK1FMgHY6WtOgy55Yq8NV9bp0dLyevC5dhmGYHavV9uIq3frSJh2uqpc9JEALrx+rSYNj2vTdxmaXVu4o1SufHtDaPV8tx98nIkhXZyTpuvH9GEUB0KUoJkAH5O4/pjnPbFCzy63fzEjVTV/eUmy25Z8d1j1L8lTf5NKgPmH6x9xMpcSEdWhb+4+2jKIs2XRQ5TUNkqQgm0VLbpuo0UlRHkwNAF9h8ivQARn9e+kXl4yQJP3hPzu0+cAxU/O4XG4tWLlb817ZrPoml84b2kdL553V4VIiSf17h+n/XTxcG+6fqqe/P1ajk+xqaHbp0RW7PZgcADqGYgL8HzeflaJLRsWpyenWnS9vNm3hsrpGp37y6hYtWFkgSfrh2QO06KZMRQYHeGT7AVaLLj4jXo9fmy6LIa3edUTbDlZ5ZNsA0FEUE+D/MAxDf549WgNiwnSoql53L86Ty9W9VzwPV9Xp6mfWa/m2wwqwGvrL7NF64LJUWS2en/OSEhOmK9ISJUlPrirw+PYBoD0oJsBJRAQHaOH3xyo4wKI1u48oa9Webtv3lgPHdPmT67S92KHosEC9cuuZuiYzuUv3OW/KIBmG9N/PS7WzxNGl+wKA06GYAKcwPC5SD81sWQn20ZW7tbag/Du+0XlLtxzUnGc/0ZHqBg2LjdDb885SZkp0l+93cN8IXXJGvCQpa9XeLt8fAJwKd+UA3+G+Nz/TaxuL1Cs0QJeMile8PVixkcGKt4cozh6kOHtIp9c8cbnceuSDXVq4uqUUTBsRqwXXpnXrWir5hxy65PGPZRjSyvnnaVCf8G7bNwD/19bzt/etIAV4md9cPlKfHaxS/mGHXv70wEk/ExFkU6w9WPH2YMVFBivO3vLz9RLTKzTgpOui1DQ06+7X8rRyR6kk6fbJg/Q/Fw6TpQvmk5xOakKkpo3oq5U7yvTUqr362zVjunX/ACAxYgK0SU1Ds97dekiHKutU4qjX4ap6lVTVq8RRr+r65jZtI9BmaS0tJwpMbGSwXt9UpJ0l1Qq0WfTn2aM0Kz2pi/80p5ZXVKmZWetktRhadc9k9evNomsAPIMRE8CDwoNsunZ8v5O+V9PQrJKqepV+WVha/reutbiUVNWrvKZRjc0uHag4rgMVx7+1jZjwID17Y4bG9uvV1X+U00pLjtI5Q2L0cUG5Fn601+eetgzA91FMgE4KD7JpcN9wDe576jkZDc1OlTkaWotKSdVXJSYk0Kr5FwxVQlRIN6Y+tZ+eP0QfF5Trjdwi/WTqYK/JBaBnoJgA3SDIZlVydKhPPI8mMyVaEwZE69PCCj275gv95vKRZkcC0INwuzCAb/np+UMkSa/mHFBZdb3JaQD0JBQTAN8yaVBvpfeLUkOzS89/XGh2HAA9CMUEwLcYhqGfTm0ZNfnXJ/tNe14QgJ6HYgLgpCYP66MzEiN1vNGpRWsZNQHQPSgmAE7KMAzdOaVl1OTF9ftUVddkciIAPQHFBMApXZgaq2GxEapuaNaL6/eZHQdAD0AxAXBKFouheVMHS5IWrStUTUPbVrkFgI6imAA4rUtHxWtgTJgqjzfpX5/sNzsOAD9HMQFwWlaLoTumtIyaPP/xF6prdJqcCIA/o5gA+E5XpCUoqVeIymsa9WrOyZ+wDACeQDEB8J0CrBbdMbll1OSZNXvV0MyoCYCu0e3FpKioSJMnT1ZqaqpGjx6tJUuWdHcEAB0wOyNR8fZglToatGTTQbPjAPBT3V5MbDabFixYoPz8fH3wwQe6++67VVtb290xALRTkM2qH587UJK0cPVeNTldJicC4I+6vZjEx8crLS1NkhQXF6eYmBhVVFR0dwwAHXDt+H6KCQ9ScWWdlm0pNjsOAD/U7mKyZs0azZgxQwkJCTIMQ8uWLfvWZ7KyspSSkqLg4GBNmDBBOTk5J91Wbm6unE6nkpOT2x0cQPcLDrDqR+cOkCQ9tXqvnC63yYkA+Jt2F5Pa2lqNGTNGWVlZJ31/8eLFmj9/vh588EFt3rxZY8aM0UUXXaSysrJvfK6iokI33nijnn322Y4lB2CK6yf0V6/QABWW1+qDz0vMjgPAz7S7mEyfPl0PPfSQZs2addL3H330Ud166626+eablZqaqqefflqhoaFatGhR62caGho0c+ZM3XfffZo0adJp99fQ0CCHw/GNHwDmCQuy6ZpxLaOcH+SXmpwGgL/x6ByTxsZG5ebmatq0aV/twGLRtGnTtGHDBkmS2+3WTTfdpKlTp+qGG274zm0+/PDDstvtrT9c9gHMN3V4X0nS6l1lXM4B4FEeLSbl5eVyOp2KjY39xuuxsbEqKWkZ8l23bp0WL16sZcuWKS0tTWlpadq2bdspt3n//ferqqqq9aeoqMiTkQF0QEb/XooMtunY8SblFVWaHQeAH7F19w7PPvtsuVxtv80wKChIQUFBXZgIQHvZrBadO7SP3v3ssFbtLFNG/15mRwLgJzw6YhITEyOr1arS0m9edy4tLVVcXJwndwXAZCcu53y4s+w7PgkAbefRYhIYGKiMjAxlZ2e3vuZyuZSdna2JEyd6clcATHbe0D4yDCn/sEMlVfVmxwHgJ9pdTGpqapSXl6e8vDxJUmFhofLy8nTgQMuDvebPn6/nnntOL774onbs2KHbb79dtbW1uvnmmz0aHIC5eocHaUxSlCRp1S5GTQB4RrvnmGzatElTpkxp/X3+/PmSpLlz5+qFF17QnDlzdOTIEf36179WSUmJ0tLS9P77739rQiwA3zd1eF/lFVXqw51lum58P7PjAPADhtvt9ol7/bKyspSVlSWn06ndu3erqqpKkZGRZscCerTtxVW67Im1Cg20asuvL1CQzWp2JABeyuFwyG63f+f5u9ufldNR8+bNU35+vjZu3Gh2FABfGpkQqb4RQTre6FROIc+8AtB5PlNMAHgfwzA0ZRh35wDwHIoJgE6Z8uVtw6soJgA8gGICoFPOHhKjAKuhfUeP64sjNWbHAeDjKCYAOiU8yKbxA6IlcTkHQOdRTAB02ol5JqxnAqCzKCYAOu3E8vQ5hRWqaWg2OQ0AX0YxAdBpA/uEK6V3qJqcbq0tKDc7DgAf5jPFJCsrS6mpqcrMzDQ7CoCT4O4cAJ7gM8WEBdYA73bics6qXWXykQWlAXghnykmALzb+AHRCg20qqy6QZ8fcpgdB4CPopgA8Iggm1VnDY6RxG3DADqOYgLAY05czqGYAOgoigkAjzmxnsnWg5U6WtNgchoAvohiAsBj4uzBSo2PlNstrd51xOw4AHwQxQSAR3397hwAaC+KCQCPOrGeyZrdR9TsdJmcBoCvoZgA8Ki05Cj1Cg2Qo75ZufuPmR0HgI/xmWLCyq+Ab7BaDJ03tI8k6UMu5wBoJ58pJqz8CvgOlqcH0FE+U0wA+I7zhvaRxZB2l9bo4LHjZscB4EMoJgA8Lio0UBn9e0li1ARA+1BMAHSJKawCC6ADKCYAusSJ9UzW7z2q+ianyWkA+AqKCYAuMSw2QvH2YDU0u7Rh71Gz4wDwERQTAF3CMAwu5wBoN4oJgC4zddhXxcTtdpucBoAvoJgA6DKTBvdWoM2i4so6FZTVmB0HgA+gmADoMqGBNk0c2FsSl3MAtA3FBECXmso8EwDt4DPFhGflAL7pRDHJ3X9MVcebTE4DwNv5TDHhWTmAb0qODtWQvuFyutz6qOCI2XEAeDmfKSYAfNfUES2jJtk7Sk1OAsDbUUwAdLlpI2IlSat3HVGz02VyGgDejGICoMulJ0cpKjRAVXVNyt1/zOw4ALwYxQRAl7NZLZo8tI8k7s4BcHoUEwDd4vwvL+dk+2gxcbrc2lNWo7LqerOjAH7NZnYAAD3DuUP7yGYxtKesRvuP1qp/7zCzI52S2+3Woap6bS2q1NaDldpaVKntxQ7VNDTLZjE0b8pgzZsyWIE2/tsO8DSKCYBuYQ8JUGZKtDZ8cVTZO8p0y9kDzI50Ui+sK9STq/aqvKbhW+8F2ixqbHbpsewCfZBfqr9ePVojE+wmpAT8F8UEQLc5f0TflmKys9Qri8lrOQf0m3fyJUk2i6Hh8REanRSltKQojU62a3CfcL23vUS/fnu7dhx26Ion1+mOKYN1J6MngMcYbh975KfD4ZDdbldVVZUiIyPNjgOgHQrLazXlr6tlsxja8usLFBEcYHakVivzS/Wj/90kl1u6ffIg3XX+EAUHWE/62fKaBv1q2Xa9t71EkjQ8LkJ/vXqMzkhk9AQ4lbaev6n4ALrNgJgwDYwJU7PLrY8Lys2O0yp3/zHd+epmudzSNeOS9POLhp2ylEhSTHiQFn4/Q1nfG6vosEDtLKnWFVnrtCKfBeSAzqKYAOhWJ56ds9JLVoHdU1ajH7y4UfVNLk0Z1kd/mDVKhmG06buXjo7Xip+dqwtSY+V0uXXvkq0qrqzr4sSAf6OYAOhW539tFViny9wryaWOes1dlKPK400akxylrOvHKsDavn8t9g4PUtb3xmp0kl1VdU26+7UtrG4LdILPFBOeLgz4h3EpvRQRbFNFbaPyisxbBdZR36Sb/rlRxZV1GhATpkVzxyk0sGP3AwTaLHriunSFB9m0cd8xPZ5d4OG0QM/hM8WEpwsD/iHAatHkYSce6mfOYmsNzU79+KVc7TjsUEx4kF66Zbx6hwd1apv9e4fpD7POkCQ9sWqPNuw96omoQI/jM8UEgP84/8t5JmYsT+92u/XzNz7Thi+OKizQqhduzlRydKhHtn1FWqKuzkiS2y3dvXiLKmobPbJdoCehmADoducN7SOLIe0sqdbBY8e7dd+rdx3R23mHZLMYevqGDI/f4vvbK0ZqYJ8wlToa9D9LtsrHVmQATEcxAdDteoUFalz/aEndO2rS7HTpD//ZIUn6wdkDdM6QPh7fR2igTU9eN1aBNouyd5bpn+v2eXwfgD+jmAAwxdQR3T/P5NWNRdpTVqNeoQG6Y8rgLttPakKkHrh0hCTpT+/t1I7Dji7bF+BvKCYATDHty2KyYe9R1TY0d/n+HPVNWrBityTpZxcMlT2ka1edveHM/po2IlaNTpd++87nXNIB2ohiAsAUg/qEq190qBqdLq3d0/WrwD61aq+O1jZqYJ8wXTe+X5fvzzAM/faKkQqyWfTJFxV6/8vl6wGcHsUEgCkMw2hdBTa7i1eBLao4rkXrCiVJv5g+ot2LqHVUYlSIbjtvkCTpD//ZofomZ7fsF/BlFBMAppn25SqwH+48IlcXrgL7yH93qbHZpUmDeuv8Ly8hdZfbzhukeHuwDh6r0/Mff9Gt+wZ8EcUEgGnGD4hWeJBN5TUN2lZc1SX72HLgmP699ZAMQ/rlpSPa/BwcTwkJtOq+6cMlSVmr9qqkqr5b9w/4GooJANME2iw6d2iMpK65nON2u/XQ8pbbg2ePTdLIBM+uWdJWl49J0Lj+vVTX5NSf399pSgbAV1BMAJhq6vCWyznZXbCeyXvbS5S7/5hCAqy698JhHt9+WxmGoQdnjJRhSEu3FCt3v3nPCAK8HcUEgKkmD+sjw5A+P+TQ4ao6j223odmpP73XMjrxo3MHKs4e7LFtd8SoJLuuzkiSJP3unc+7dE4N4MsoJgBMFRMepPTkKEmeXQX2pfX7daDiuPpGBOnH5w302HY7496Lhik8yKatB6u0dEux2XEAr0QxAWC680/cneOhVWCP1TbqiQ8LJEn3XjhMoYE2j2y3s/pGBOvOqS0rzv7p/Z2q6YaF5QBf4zPFJCsrS6mpqcrMzDQ7CgAPO3EL79o95apr7PxaH49lF8hR36wR8ZGa/eXlE29x81kpSukdqiPVDXoiu8DsOIDX8ZliMm/ePOXn52vjxo1mRwHgYcNiI5QYFaKGZpfW7+3cKrA5hRV6ccM+SdIDl46Q1dK9twd/lyCbVb+ekSpJWrSuUHuP1JicCPAuPlNMAPivr68Cu7ITl3Mc9U362eI8ud3S1RlJOmtwjKcietTU4bGaOryvmpxu/fadfJ6jA3wNxQSAVzhxOefDnaUdPlH/5u3PVVxZp37RoXrw8pGejOdxv74sVYFWi9bsPqIV+V27JD/gSygmALzCmQN7KzTQqlJHQ4ceePfO1kN6a0uxLIb09zljFB7kHRNeTyUlJkw/PGeAJOn3y/N5jg7wJYoJAK8QHGDVzPRESdKdr27Rm7kH2/zdQ5V1+uXSbS3fnTJYGf2juySjp82bMlhxkcEqqqjTc2t4jg4gUUwAeJHfXj5SV6Ynyuly654lW/XMR3u/87KOy+XWPa9vlaO+WWOSo/ST84d0U9rOCwuy6ReXjpAkZa3eo+JKzy0wB/gqigkArxFgteivV4/Rj85tWRDt4fd26qHlO067Suo/1hZqwxdHFRJg1YI5aQqw+ta/1maMjteEAdGqb3Lpj18+1wfoyXzrCAbg9ywWQ7+4ZIR+eUnLSMI/1hbqZ6/nqbHZ9a3P5h9y6JH/7pIk/XpGqgbEhHVrVk8wDEO/uXykLIa0fNthJsKix6OYAPBKt547UH+fM0Y2i6G38w7pBy9uVO3XVkqtb3Lq7sVb1Oh0adqIWF2bmWxi2s4ZER+pH57TMkp075KtKqo4bnIiwDwUEwBea1Z6kp6fO04hAVZ9XFCu7z33iY7WNEiS/vL+Lu0urVFMeJD+PHuUDMO7FlJrr3svHKa05ChV1TXpzlc2n3SECOgJKCYAvNrkYX31yq0T1Cs0QFsPVumqpzfotZwDWrSuUJL0yFWj1Ts8yOSUnRdos+jJ76XLHtLy5/zjf5hvgp6JYgLA66X366U3bp+kxKgQFZbX6r63Wm4NvnFif035csVYf5DUK1SPXjNGkvTC+n36z7bDJicCuh/FBIBPGNQnXG/ePknDYiO+/D1M908fYXIqzzt/RKxuO2+QJOnnb3ymfeW1JicCupfh9rGHNDgcDtntdlVVVSkyMtLsOAC6WVVdk97OK9YFqbGKt4eYHadLNDtd+t5znypnX4VGxEfqrdsnKSTQanYsoFPaev5mxASAT7GHBOjGiSl+W0okyWa16PHr0tU7LFA7Djt0x8u5TIZFj0ExAQAvFGcP1tM3ZCg4wKJVu47oZ4vz5DzNQnOAv6CYAICXykyJ1jM3jFOA1dDybYd135ufnXYVXMAfUEwAwIudN7SPnrguXRZDWpJ7UL97N/87nx8E+DKKCQB4uYvPiNcjV311G/HfV+w2ORHQdSgmAOADZmck6fdXjJQkPf7hHi3bUmxyIqBrUEwAwEfcMDFFd04ZLEm6763PlH/IYXIiwPN8pphkZWUpNTVVmZmZZkcBANP87IKhOm9oH9U3uXTbv3JVdbzJ7EiAR7HAGgD4mMrjjZrx5FoVVdRp8rA+WjQ3UxaLbz/EEP6PBdYAwE9FhQZq4fUZCrJZtHrXES3ILjA7EuAxFBMA8EFnJNr18JWjJEmPZxfow52lJicCPINiAgA+6sqxSbpxYn9J0q+Wfa6GZqfJiYDOo5gAgA+7f/oIxUYGqbiyTv+7Yb/ZcYBOo5gAgA8LCbTqnguGSZKe+HAPd+nA51FMAMDHzc5I0tDYcFXVNemp1XvMjgN0CsUEAHyc1WLo/ukjJEn/XL9PB48dNzkR0HEUEwDwA5OH9dHEgb3V2OzSox/wLB34LooJAPgBwzB0/yXDJUlL84q1vbjK5ERAx1BMAMBPjE6K0owxCXK7pT+/v9PsOECHUEwAwI/8z4XDFGA19HFBuXL3V5gdB2g3igkA+JF+vUN1ZXqSJOmpVXtNTgO0H8UEAPzMj88bKMOQsneWaWeJw+w4QLtQTADAzwzsE65LzoiXJC1czagJfAvFBAD80O2TB0mS3tl6SAeOsq4JfAfFBAD80BmJdp0zJEYut/Tsx4yawHdQTADAT90xebAk6fVNB1VWXW9yGqBtKCYA4KfOHBit9H5Ramx2adHafWbHAdqEYgIAfsowjNZRk399sl8VtY3t3kZ9k5M5KuhWFBMA8GPnD++rEfGRqmlo1n1vfia3292m71Udb9IT2QWa9KcPde4jq/Q/S7aqqq6pi9MCFBMA8GsWi6FHrhqtAKuhD/JL9UrOgdN+vq7RqYff26FJf8rW31bsbh1lWZJ7UBcvWKOPdh/pjtjowSgmAODnzki06+cXtTzg7/fv5mtPWfVJP3ekukHXPveJnvnoC9U2OjU8LkKPXZum1350plJ6h+pwVb3mLsrRE9kF3RkfPQzFBAB6gB+cPUDnDIlRfZNLP301Tw3Nzm+8X1BarZlZ67S1qFJRoQF69oYMvXfXOboiLVFnDuyt9+46VzdNSpEkLcguUEHpycsN0FmGu60XHL2Ew+GQ3W5XVVWVIiMjzY4DAD6jzFGvix/7WBW1jbo2M1nnj4hVk9Olo7WN+sv7O1Vd36yU3qH6583jNSAm7KTbuPWlTVqRX6pzh/bRizdnyjCMbv5TwFe19fxNMQGAHmRFfqlufWnTSd/LTOmlZ28Yp15hgaf8/r7yWl3w94/U5HRr0U3jNHV4bFdFhZ9p6/nb1o2ZAAAmuyA1Vj+/eJje21Yim9VQgNWiAKuh0UlRunvaEAXZrKf9fkpMmG45a4CeWfOFHnp3h84e3EeBNmYFwHMYMQEAtEt1fZOm/HW1ymsa9cClI/TDcwaaHQk+oK3nb2ouAKBdIoIDdO+FwyRJj2UXqOo465vAcygmAIB2u3pcsobFRqi6vlkvbthndhz4EZ8pJllZWUpNTVVmZqbZUQCgx7NaDN0xZZAkadG6QtU2NJucCP7CZ4rJvHnzlJ+fr40bN5odBQAg6bLRCUrpHarK40169TtWlAXaymeKCQDAu1gthm47r2XU5LmPv/jWom1AR1BMAAAdduXYJMXbg1XqaNCbucVmx4EfoJgAADos0GbRrV/eLvz0R3vV7HSZnAi+jmICAOiU68b3U3RYoA5UHNerG4vMjgMfRzEBAHRKSKBVP506WJL0l/d3qsxRb3Ii+DKKCQCg026YmKIxSXZV1zfrt+/kmx0HPoxiAgDoNKvF0B+vHCWrxdDybYf14c5SsyPBR1FMAAAeMTLBrh+cPUCS9Ktln7PoGjqEYgIA8Ji7pw1RYlSIiivrdOOiHFXUNpodCT6GYgIA8JjQQJsevy5dkcE25e4/ptkL12tfea3ZseBDKCYAAI/K6N9Lb94+SYlRISosr9WVC9drw96jZseCj6CYAAA8bkhshJbOm6RRiXZV1Dbq+uc/0RPZBXK53GZHg5ejmAAAukTfiGAt/vGZuiojSS639LcVuzX3nzmqqmsyOxq8GMUEANBlQgNt+uvVY/TIVaMVHGDRxwXluvWlTapv4oF/ODmKCQCgy109Lllv3DZJEUE25RRW6O7X8uTksg5OgmICAOgWZyTa9eyN4xRotej9z0v067e3y+2mnOCbKCYAgG4zcVBvLbg2TYYhvfzpAS1at8/sSPAyFBMAQLe6ZFS8Hrg0VZL0h+X5WltQbnIieBOKCQCg291yVkrr3TrzXtms/UdZhA0tKCYAgG5nGIYemnmG0pKjVFXXpBsX5WhrUaXZseAFKCYAAFMEB1j17A0ZSowK0f6jx3XlwvX6+4rdKqo4rur6JibG9lCG28f+yTscDtntdlVVVSkyMtLsOACATqo83qgHlm3Xu58dPun7hiGN699L8y8YpomDendzOnhKW8/fFBMAgFf499ZD+vuK3SqurFNjs+uknzlnSIz+PidNMeFB3ZwOnUUxAQD4rPomp2oamiVJNfXNWrSuUK/mHFCT063RSXa9euuZCguymZwS7dHW8zdzTAAAXic4wKqY8CDFhAcpJSZMv7viDC3/6TnqFRqgzw5W6bZ/5Z5yVAW+jWICAPAJQ2MjtOimTIUEWPVxQbkeWLbN7EjoAhQTAIDPSO/XS09dP1YWQ3p900G9vqnI7EjwMIoJAMCnTBneV/MvGCpJ+tWy7dpx2GFyIngSxQQA4HPumDxY5w3to4Zml+54ebPKaxrMjgQPoZgAAHyOxWLo73PSlBgVosLyWl337Cc6Uk058QcUEwCAT4oOC9S/fjhBcZHBKiir0XXPfaKN+ypYMdbHsY4JAMCn7Suv1XXPfaLDVfWSpOFxEZoyvK9GJdo1aVBvRYUGmpwQEgusAQB6kOLKOj2RXaBlecWqb/pqfRN7SIB+dVmqZo9NlGEYJiYExQQA0ONU1TXp/e2HlVdUpU++OKrC8lpJ0rQRsVr4/bEKsDKDwSwUEwBAj9bkdOn5jwv195W71djs0m3nDdJ904ebHavHYkl6AECPFmC16PbJg/TYnDRJ0tMf7dWqXWXmhsJ3opgAAPza9FHxunFif0nS/MV5KnPUm5wIp0MxAQD4vV9cMkIjEyJ17HiTfv7mZ9xS7MUoJgAAvxccYNWCOWkKtFm0etcRvZJzwOxIOAWKCQCgRxgSG6GfXzRMkvTQuzu0Mr/U5EQ4GZvZAQAA6C63nDVAawrKtWb3Ef3wpU26OiNJsZHBanK6VN/kVHRYkOZkJivOHmx21B6L24UBAD1KY7NLf3pvpxatKzzp+wFWQ1emJ+nnFw9T7/Cgbk7nv1jHBACA01i9q0yrdpbJMAwFWA0FB1j1aWGFcgorJElRoQGaf8FQXZ2RrJBAq8lpfR/FBACADti0r0K/evtz7TjskNRSUL43vp/mTkpRbCSXeDrKqxdYmzVrlnr16qWrrrrKjN0DAHBK41Ki9c6dZ+l3V4xUv+hQVR5v0lOr9+rsP3+ohav3cqtxFzOlmNx111166aWXzNg1AADfyWa16MaJKVp172Q9c0OGxqdEq8np1p/f36lfLN2mZqfruzeCDjGlmEyePFkRERFm7BoAgDazWgxdNDJOr982Ub+ZkSqLIb2aU6T739rGyEkXaXcxWbNmjWbMmKGEhAQZhqFly5Z96zNZWVlKSUlRcHCwJkyYoJycHE9kBQDANDedNUBPXT9WVouhJbkH9YflO+RyUU48rd3FpLa2VmPGjFFWVtZJ31+8eLHmz5+vBx98UJs3b9aYMWN00UUXqayMBycBAHzbxWfE6+ErR0mSnl9bqFtf2qSyap6940ntXmBt+vTpmj59+inff/TRR3Xrrbfq5ptvliQ9/fTTWr58uRYtWqT77ruv3QEbGhrU0NDQ+rvD4Wj3NgAA8JRrxiVLkh5Ytl3ZO8s04Y/ZGpVo14i4SI1KsuuC1Fju3ukEj84xaWxsVG5urqZNm/bVDiwWTZs2TRs2bOjQNh9++GHZ7fbWn+TkZE/FBQCgQ64Zl6yld0zSmOQoud3SZwertHhTkR5Ytl0T/pitW1/apF0l1WbH9EkeXZK+vLxcTqdTsbGx33g9NjZWO3fubP192rRp2rp1q2pra5WUlKQlS5Zo4sSJJ93m/fffr/nz57f+7nA4KCcAANONTLDr7XlnqdRRr08LK1RQWq11e8q1+UClVuSXKntHqW47b5DunjZUgTYeTddWpjwrZ+XKlW3+bFBQkIKCWBIYAOCdYiODdfmYBEnSPRcO056yGv3tg116b3uJnlq9V2v3lCvre2OVHB1qclLf4NEKFxMTI6vVqtLSbz6xsbS0VHFxcZ7cFQAAXmlw33At/H6GFl4/VlGhAfrsYJUue2Kt3s4r5hbjNvBoMQkMDFRGRoays7NbX3O5XMrOzj7lpRoAAPzR9FHxWv7TczQmOUpVdU2667U83bgoR5sPHDM7mldr96Wcmpoa7dmzp/X3wsJC5eXlKTo6Wv369dP8+fM1d+5cjRs3TuPHj9eCBQtUW1vbepcOAAA9RWJUiJb8eKKe/mivnvxwjz4uKNfHBeW6eGScfnnpCC7vnES7H+K3evVqTZky5Vuvz507Vy+88IIk6cknn9QjjzyikpISpaWl6fHHH9eECRM8EpiH+AEAfNH+o7XKWrVHb24ultPlVmigVQ9cmqrrxifLMAyz43U5ni4MAIAX2lVSrV+9vV05hRWSpLH9onTvRcM0cWBvvy4ofldMsrKylJWVJafTqd27d1NMAAA+y+Vya9G6Qj26YreONzolSUNjw3XvhcN0QWqsXxYUvysmJzBiAgDwF6WOej3xYYHe2lzcWlDOH95Xf5o9Wn0i/GupDIoJAAA+wlHfpGc+2qvn1hSq0emSPSRA91w4VHMykxVks5odzyMoJgAA+JidJQ79bPFW7Tjc8ly4mPBA3TQpRXMnpSgiOMDkdJ1DMQEAwAc1O116JeeAFq7eq8NVLU8ujg4L1L0XDtOczGRZLb45/4RiAgCAD2t2urR822E9ll2gL47USpKG9A3XfdOHa+rwvj43QZZiAgCAH2hyuvS/G/brsewCVdU1SZImDIjWfdOHK71fL5PTtR3FBAAAP1JV16SnVu/RP9ftU2OzS5J0zpAY3XX+EI1LiTY53XejmAAA4IeKK+v09xW7tXRLywqyknRhaqx+dVmqVy9x73fFhAXWAAD4SlHFcT21eo9e33RQTpdbAVZDczKT9aNzBqlfb+8rKH5XTE5gxAQAgK/sKqnW79/N19o95ZIkq8XQdeOTddf5Q71qkTaKCQAAPciGvUe18KO9WrP7iCQpNNCqOZnJuuWsAV5xiYdiAgBAD7Rh71H96f2d2lpUKallBOWKtATdOWWwBvYJNy0XxQQAgB7K7XZrTUG5nl2zV+v2HJUkWQzp8jEJunPqEA3u2/0FhWICAAC0tahSj2cXKHtnmSTJMKQZoxN097Qh3TqCQjEBAACtthdX6bHsAq3IL5XUconnmnFJuuv8oYqzB3f5/ikmAADgW7YXV+nRFbv14ZcjKIE2i2aPTdQPzh7YpZd4KCYAAOCUNu2r0J/f36mN+45JarnEc+moeN09bYgG943w+P4oJgAA4LTcbrc27T+mZz76Qit3tFziMQzpL7NH6+pxyR7dV1vP3zaP7rULfX3lVwAA0HmGYSgzJVqZKdHKP+TQY9m7tXrXEZ0zpI95mRgxAQAAJ5Q56tU30vOTYdt6/rZ4fM8AAMBndUUpaQ+KCQAA8BoUEwAA4DUoJgAAwGtQTAAAgNegmAAAAK9BMQEAAF6DYgIAALwGxQQAAHgNnykmWVlZSk1NVWZmptlRAABAF2FJegAA0OVYkh4AAPgcigkAAPAaFBMAAOA1bGYHaK8TU2IcDofJSQAAQFudOG9/19RWnysm1dXVkqTk5GSTkwAAgPaqrq6W3W4/5fs+d1eOy+XS0KFDlZubK8Mw2vSdzMxMbdy48bSfcTgcSk5OVlFREXf7fKktf29m6u58XbU/T223M9vpyHfb+x2Ow47hOOye/XEcfqWrjkO3263q6molJCTIYjn1TBKfGzGxWCwKDAw8bdv6v6xWa5v/ciMjI/kX4pfa8/dmhu7O11X789R2O7Odjny3vd/hOOwYjsPu2R/H4bd1xXHYlnO3T05+nTdvXpd+Hi28/e+tu/N11f48td3ObKcj3+U47B7e/vfGcei57XActvC5SzldhYXbAPNxHALmM/s49MkRk64QFBSkBx98UEFBQWZHAXosjkPAfGYfh4yYAAAAr8GICQAA8BoUEwAA4DUoJgAAwGtQTAAAgNegmAAAAK9BMWmjd999V8OGDdOQIUP0/PPPmx0H6JFmzZqlXr166aqrrjI7CtAjFRUVafLkyUpNTdXo0aO1ZMkSj++D24XboLm5WampqVq1apXsdrsyMjK0fv169e7d2+xoQI+yevVqVVdX68UXX9Qbb7xhdhygxzl8+LBKS0uVlpamkpISZWRkaPfu3QoLC/PYPhgxaYOcnByNHDlSiYmJCg8P1/Tp0/XBBx+YHQvocSZPnqyIiAizYwA9Vnx8vNLS0iRJcXFxiomJUUVFhUf30SOKyZo1azRjxgwlJCTIMAwtW7bsW5/JyspSSkqKgoODNWHCBOXk5LS+d+jQISUmJrb+npiYqOLi4u6IDviNzh6HADrPk8dhbm6unE6nkpOTPZqxRxST2tpajRkzRllZWSd9f/HixZo/f74efPBBbd68WWPGjNFFF12ksrKybk4K+C+OQ8B8njoOKyoqdOONN+rZZ5/1fEh3DyPJvXTp0m+8Nn78ePe8efNaf3c6ne6EhAT3ww8/7Ha73e5169a5Z86c2fr+XXfd5X755Ze7JS/gjzpyHJ6watUq9+zZs7sjJuDXOnoc1tfXu8855xz3Sy+91CW5esSIyek0NjYqNzdX06ZNa33NYrFo2rRp2rBhgyRp/Pjx2r59u4qLi1VTU6P33ntPF110kVmRAb/TluMQQNdqy3Hodrt10003aerUqbrhhhu6JEePLybl5eVyOp2KjY39xuuxsbEqKSmRJNlsNv3tb3/TlClTlJaWpnvuuYc7cgAPastxKEnTpk3T1Vdfrf/85z9KSkqitAAe1JbjcN26dVq8eLGWLVumtLQ0paWladu2bR7NYfPo1vzY5Zdfrssvv9zsGECPtnLlSrMjAD3a2WefLZfL1aX76PEjJjExMbJarSotLf3G66WlpYqLizMpFdCzcBwC5vOW47DHF5PAwEBlZGQoOzu79TWXy6Xs7GxNnDjRxGRAz8FxCJjPW47DHnEpp6amRnv27Gn9vbCwUHl5eYqOjla/fv00f/58zZ07V+PGjdP48eO1YMEC1dbW6uabbzYxNeBfOA4B8/nEcdgl9/p4mVWrVrklfetn7ty5rZ954okn3P369XMHBga6x48f7/7kk0/MCwz4IY5DwHy+cBzyrBwAAOA1evwcEwAA4D0oJgAAwGtQTAAAgNegmAAAAK9BMQEAAF6DYgIAALwGxQQAAHgNigkAAPAaFBMAAOA1KCYAAMBrUEwAAIDXoJgAAACv8f8BDhgZVI1cZT4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.loglog(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCANTRALayer(tf.Module):\n",
    "    def __init__(self, model, lambda_=0.1, tau=1, gamma=0.9):\n",
    "        super(SCANTRALayer, self).__init__()\n",
    "        self.lambda_ = tf.Variable(tf.ones(1) * lambda_, trainable=True)\n",
    "        self.tau = tf.Variable(tf.ones(1) * tau, trainable=True)\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        self.B = []\n",
    "        for p in model.trainable_variables:\n",
    "            self.B.append(tf.Variable(tf.ones(p.shape), trainable=True))\n",
    "            \n",
    "    '''\n",
    "    def forward(self, model, criterion, X_train_tensor, y_train_tensor):\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            loss = criterion(model(X_train_tensor), y_train_tensor)\n",
    "\n",
    "        for i, p in enumerate(model.trainable_variables):\n",
    "            K = tape.gradient(loss, p)\n",
    "            #print(p.shape)\n",
    "            # Local optimization step\n",
    "            if len(p.shape) == 1:\n",
    "                I = tf.ones_like(self.B[i])\n",
    "                H = self.B[i]**2 + self.tau*I\n",
    "                M = 1/((2*self.lambda_ + self.tau)*I + H)\n",
    "                w_hat = M*(H*p) - K\n",
    "                \n",
    "            else:\n",
    "                I = self.tau * tf.eye(tf.shape(self.B[i])[0])\n",
    "                H = tf.matmul(self.B[i], tf.transpose(self.B[i])) + self.tau*I\n",
    "                M = tf.linalg.inv((2*self.lambda_ + self.tau)*I + H)\n",
    "                w_hat = tf.linalg.matmul(M, tf.linalg.matmul(H, p) - K)\n",
    "\n",
    "            p.assign_add(self.gamma * (w_hat - p))\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCANTRANet(tf.Module):\n",
    "    def __init__(self, model, T=10, lambda_=0.1, tau=25, gamma=0.8):\n",
    "        super(SCANTRANet, self).__init__()\n",
    "        self.T = T\n",
    "        self.lambda_0 = tf.Variable(tf.ones(T) * lambda_, trainable=False)\n",
    "        self.tau_0 = tf.Variable(tf.ones(T) * tau, trainable=False)\n",
    "        self.gamma_0 = tf.Variable(tf.ones(T) * gamma, trainable=False)\n",
    "\n",
    "        for i in range(self.T):\n",
    "            self.gamma_0[i].assign(self.gamma_0[i] * 0.99**i)\n",
    "\n",
    "        self.SCANTRA_layers = [SCANTRALayer(model, self.lambda_0[i], self.tau_0[i], self.gamma_0[i]) for i in range(self.T)]\n",
    "        self.meta_optimizer = tf.optimizers.Adam(learning_rate=1e-1, decay=5e-4)\n",
    "\n",
    "    @tf.function\n",
    "    def step(self, model, criterion, epoch, X_train_tensor, y_train_tensor):\n",
    "        layer = self.SCANTRA_layers[epoch]\n",
    "        params = []\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            loss = criterion(model(X_train_tensor), y_train_tensor)\n",
    "\n",
    "            tape.watch(self.trainable_variables)\n",
    "            for i, p in enumerate(model.trainable_variables):\n",
    "                K = tape.gradient(loss, p)\n",
    "                #print(p.shape)\n",
    "                # Local optimization step\n",
    "                if len(p.shape) == 1:\n",
    "                    I = tf.ones_like(layer.B[i])\n",
    "                    H = layer.B[i]**2 + layer.tau*I\n",
    "                    M = 1/((2*layer.lambda_ + layer.tau)*I + H)\n",
    "                    w_hat = M*((H*p) - K)\n",
    "                    \n",
    "                else:\n",
    "                    I = layer.tau * tf.eye(tf.shape(layer.B[i])[0])\n",
    "                    H = tf.matmul(layer.B[i], tf.transpose(layer.B[i])) + layer.tau*I\n",
    "                    M = tf.linalg.inv((2*layer.lambda_ + layer.tau)*I + H)\n",
    "                    w_hat = tf.linalg.matmul(M, tf.linalg.matmul(H, p) - K)\n",
    "\n",
    "                p.assign_add(layer.gamma * (w_hat - p))\n",
    "\n",
    "\n",
    "            #tape.watch(self.trainable_variables)\n",
    "            tape.watch(model.trainable_variables)\n",
    "            loss = criterion(model(X_train_tensor), y_train_tensor)\n",
    "            \n",
    "            '''\n",
    "            tape.watch(self.trainable_variables)\n",
    "            self.SCANTRA_layers[epoch].forward(model, criterion, X_train_tensor, y_train_tensor)\n",
    "            outputs = model(X_train_tensor, training=True)\n",
    "            loss = criterion(y_train_tensor, outputs)\n",
    "            '''\n",
    "\n",
    "        gradients = tape.gradient(loss, list(model.trainable_variables) + list(self.trainable_variables))\n",
    "        optimizer_gradients = gradients[len(self.trainable_variables):]\n",
    "        #tf.print(gradients)\n",
    "\n",
    "        self.meta_optimizer.apply_gradients(zip(optimizer_gradients, self.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation='relu', input_shape=(13,)),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Define the loss function\n",
    "criterion = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "# Initialize the neural optimizer\n",
    "optimizer = SCANTRANet(model, T = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Leonardo\\AppData\\Local\\Temp\\ipykernel_15316\\2371878125.py\", line 57, in step  *\n        self.meta_optimizer.apply_gradients(zip(optimizer_gradients, self.trainable_variables))\n    File \"c:\\Users\\Leonardo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 689, in apply_gradients  **\n        grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\n    File \"c:\\Users\\Leonardo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\utils.py\", line 77, in filter_empty_gradients\n        raise ValueError(\n\n    ValueError: No gradients provided for any variable: (['Variable:0', 'Variable:0', 'Variable:0', 'Variable:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'Variable:0' shape=(13, 30) dtype=float32>), (None, <tf.Variable 'Variable:0' shape=(30,) dtype=float32>), (None, <tf.Variable 'Variable:0' shape=(30, 1) dtype=float32>), (None, <tf.Variable 'Variable:0' shape=(1,) dtype=float32>)).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [69], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m train_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m)):\n\u001b[0;32m      4\u001b[0m     \n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Our beautiful neural optimizer\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m#optimizer.transfer(model)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Store loss value\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(criterion(model(X_train_tensor), y_train_tensor))\n",
      "File \u001b[1;32mc:\\Users\\Leonardo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filews2t_7sr.py:59\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__step\u001b[1;34m(self, model, criterion, epoch, X_train_tensor, y_train_tensor)\u001b[0m\n\u001b[0;32m     57\u001b[0m gradients \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tape)\u001b[38;5;241m.\u001b[39mgradient, (ag__\u001b[38;5;241m.\u001b[39mld(loss), ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mlist\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(model)\u001b[38;5;241m.\u001b[39mtrainable_variables,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope) \u001b[38;5;241m+\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mlist\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mtrainable_variables,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     58\u001b[0m optimizer_gradients \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(gradients)[ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mlen\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mtrainable_variables,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope):]\n\u001b[1;32m---> 59\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta_optimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer_gradients\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Leonardo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:689\u001b[0m, in \u001b[0;36mOptimizerV2.apply_gradients\u001b[1;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_gradients\u001b[39m(\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28mself\u001b[39m, grads_and_vars, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, experimental_aggregate_gradients\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    650\u001b[0m ):\n\u001b[0;32m    651\u001b[0m     \u001b[38;5;124;03m\"\"\"Apply gradients to variables.\u001b[39;00m\n\u001b[0;32m    652\u001b[0m \n\u001b[0;32m    653\u001b[0m \u001b[38;5;124;03m    This is the second part of `minimize()`. It returns an `Operation` that\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;124;03m      RuntimeError: If called in a cross-replica context.\u001b[39;00m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 689\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_empty_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    690\u001b[0m     var_list \u001b[38;5;241m=\u001b[39m [v \u001b[38;5;28;01mfor\u001b[39;00m (_, v) \u001b[38;5;129;01min\u001b[39;00m grads_and_vars]\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name):\n\u001b[0;32m    693\u001b[0m         \u001b[38;5;66;03m# Create iteration if necessary.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Leonardo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\utils.py:77\u001b[0m, in \u001b[0;36mfilter_empty_gradients\u001b[1;34m(grads_and_vars)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filtered:\n\u001b[0;32m     76\u001b[0m     variable \u001b[38;5;241m=\u001b[39m ([v\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m _, v \u001b[38;5;129;01min\u001b[39;00m grads_and_vars],)\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo gradients provided for any variable: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvariable\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvided `grads_and_vars` is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrads_and_vars\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     80\u001b[0m     )\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vars_with_empty_grads:\n\u001b[0;32m     82\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m     83\u001b[0m         (\n\u001b[0;32m     84\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGradients do not exist for variables \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m when minimizing the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     88\u001b[0m         ([v\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m vars_with_empty_grads]),\n\u001b[0;32m     89\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Leonardo\\AppData\\Local\\Temp\\ipykernel_15316\\2371878125.py\", line 57, in step  *\n        self.meta_optimizer.apply_gradients(zip(optimizer_gradients, self.trainable_variables))\n    File \"c:\\Users\\Leonardo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 689, in apply_gradients  **\n        grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\n    File \"c:\\Users\\Leonardo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\utils.py\", line 77, in filter_empty_gradients\n        raise ValueError(\n\n    ValueError: No gradients provided for any variable: (['Variable:0', 'Variable:0', 'Variable:0', 'Variable:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'Variable:0' shape=(13, 30) dtype=float32>), (None, <tf.Variable 'Variable:0' shape=(30,) dtype=float32>), (None, <tf.Variable 'Variable:0' shape=(30, 1) dtype=float32>), (None, <tf.Variable 'Variable:0' shape=(1,) dtype=float32>)).\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "\n",
    "for epoch in tqdm(range(100)):\n",
    "    \n",
    "    # Our beautiful neural optimizer\n",
    "    optimizer.step(model, criterion, epoch, X_train_tensor, y_train_tensor)\n",
    "    #optimizer.transfer(model)\n",
    "    \n",
    "    # Store loss value\n",
    "    train_losses.append(criterion(model(X_train_tensor), y_train_tensor))\n",
    "    \n",
    "    '''\n",
    "    # Print progress\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{100}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test_tensor)\n",
    "        test_loss = criterion(test_outputs, y_test_tensor)\n",
    "        #print(f'Test Loss: {test_loss.item():.4f}')\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(train_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
