{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_matrices(n_samples, n, condition_number=10):\n",
    "    A_matrices = []\n",
    "    A_inv_matrices = []\n",
    "    \n",
    "    for _ in range(n_samples):\n",
    "        # Generate a random matrix\n",
    "        U, _, Vt = np.linalg.svd(np.random.randn(n, n))\n",
    "        s = np.linspace(1, condition_number, n)\n",
    "        S = np.diag(s)\n",
    "        A = U @ S @ Vt\n",
    "        \n",
    "        # Compute the inverse\n",
    "        A_inv = np.linalg.inv(A)\n",
    "        \n",
    "        A_matrices.append(A)\n",
    "        A_inv_matrices.append(A_inv)\n",
    "    \n",
    "    return np.array(A_matrices), np.array(A_inv_matrices)\n",
    "\n",
    "n_samples = 1000\n",
    "matrix_size = 5\n",
    "\n",
    "A_matrices, A_inv_matrices = generate_matrices(n_samples, matrix_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " A_input (InputLayer)           [(None, 5, 5)]       0           []                               \n",
      "                                                                                                  \n",
      " X_input (InputLayer)           [(None, 5, 5)]       0           []                               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 25)           0           ['A_input[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 25)           0           ['X_input[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 50)           0           ['flatten[0][0]',                \n",
      "                                                                  'flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          6528        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          16512       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 25)           3225        ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 5, 5)         0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 26,265\n",
      "Trainable params: 26,265\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(matrix_size):\n",
    "    # Define inputs\n",
    "    A_input = Input(shape=(matrix_size, matrix_size), name='A_input')\n",
    "    X_input = Input(shape=(matrix_size, matrix_size), name='X_input')\n",
    "    \n",
    "    # Flatten the inputs\n",
    "    A_flat = tf.keras.layers.Flatten()(A_input)\n",
    "    X_flat = tf.keras.layers.Flatten()(X_input)\n",
    "    \n",
    "    # Concatenate the inputs\n",
    "    concatenated = Concatenate()([A_flat, X_flat])\n",
    "    \n",
    "    # Dense layers for refinement\n",
    "    hidden = Dense(128, activation='relu')(concatenated)\n",
    "    hidden = Dense(128, activation='relu')(hidden)\n",
    "    \n",
    "    # Output layer\n",
    "    delta_X_flat = Dense(matrix_size * matrix_size)(hidden)\n",
    "    delta_X = tf.keras.layers.Reshape((matrix_size, matrix_size))(delta_X_flat)\n",
    "    \n",
    "    # Define the model\n",
    "    model = Model(inputs=[A_input, X_input], outputs=delta_X)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model(matrix_size)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, A_matrices, A_inv_matrices, epochs=100, batch_size=32):\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    mse_loss = MeanSquaredError()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Shuffle the data\n",
    "        indices = np.arange(len(A_matrices))\n",
    "        np.random.shuffle(indices)\n",
    "        A_matrices = A_matrices[indices]\n",
    "        A_inv_matrices = A_inv_matrices[indices]\n",
    "        \n",
    "        for i in range(0, len(A_matrices), batch_size):\n",
    "            A_batch = A_matrices[i:i + batch_size]\n",
    "            A_inv_batch = A_inv_matrices[i:i + batch_size]\n",
    "            \n",
    "            # Initialize the approximation with the identity matrix\n",
    "            X_approx = np.tile(np.eye(matrix_size), (len(A_batch), 1, 1))\n",
    "            \n",
    "            # Perform iterative refinement\n",
    "            for _ in range(10):  # Number of refinement steps\n",
    "                with tf.GradientTape() as tape:\n",
    "                    delta_X = model([A_batch, X_approx])\n",
    "                    X_approx += delta_X\n",
    "                    loss = mse_loss(A_batch @ X_approx, np.tile(np.eye(matrix_size), (len(A_batch), 1, 1)))\n",
    "                \n",
    "                gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "            \n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss.numpy()}')\n",
    "\n",
    "train_model(model, A_matrices, A_inv_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Test Loss: 1.05301112189169\n"
     ]
    }
   ],
   "source": [
    "# Generate test data\n",
    "n_test_samples = 100\n",
    "A_test, A_inv_test = generate_matrices(n_test_samples, matrix_size)\n",
    "\n",
    "def evaluate_model(model, A_test, A_inv_test):\n",
    "    X_approx = np.tile(np.eye(matrix_size), (len(A_test), 1, 1))\n",
    "    \n",
    "    for _ in range(10):\n",
    "        delta_X = model.predict([A_test, X_approx])\n",
    "        X_approx += delta_X\n",
    "    \n",
    "    mse_loss = MeanSquaredError()\n",
    "    test_loss = mse_loss(A_test @ X_approx, np.tile(np.eye(matrix_size), (len(A_test), 1, 1)))\n",
    "    print(f'Test Loss: {test_loss.numpy()}')\n",
    "\n",
    "evaluate_model(model, A_test, A_inv_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
